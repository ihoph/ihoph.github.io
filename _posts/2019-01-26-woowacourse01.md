---
layout: post
title:  우아한테코크스 1기 테코톡 정리
date:   2020-01-26 22:10:00 +0800
categories: 우아한테크코스
tag: Computer Science
sitemap :
  changefreq : daily
  priority : 1.0

---
이 포스트에서는 [우아한테크코스 1기 테코톡](https://www.youtube.com/watch?v=NfJjaGjVceo&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH) 중 지식 공유 목적의 발표들을 정리해보겠습니다.

우아한테크코스 2기에 참여할 수 있게 되면서, 1기분들이 어떤 공부를 했는 지, 어떤 고민을 했는 지 궁금해졌습니다.

공부하시고 발표하신 것들이 모두 공개되어있기 때문에 쉽게 접할 수 있었습니다.

발표들을 보면서 알짜배기 정보들이 모여있다고 느꼈습니다. 깊이 공부하시고 중요한 내용만 짚어주시니, 짧은 시간에 많은 것을 공부한 느낌이 들었습니다. 아래 내용들을 깊이 이해했다고 할 수는 없지만, 대략적으로 이러한 내용이다 정도는 알게된 것 같습니다. 좋은 발표해주신 1기분들께 감사드립니다.

제가 정리한 내용은 어느정도라도 이해한 것들만 적었기 때문에, 발표의 모든 내용을 포함하지 않습니다. 그리고 저는 대부분 모르는 것들이었기 때문에 모든 발표가 유익했지만, 이미 내용을 알고 계신 분들에게는 그렇지 않을 수 있습니다.

따라서, 제가 정리한 내용을 보고 '이 발표가 대략 이러한 내용을 다루니 한번 봐야겠다' 정도로, 즉 **관심가는 영상을 찾는 용도로 활용**해주시면 좋을 것 같습니다.



## 목차

1. [OCP와 전략패턴 - 베디](#OCP와_전략패턴_베디)
2. [DTO vs VO - 지노&비모](#DTO_VS_VO_지노&비모)
3. [MVC 패턴 - 해리&션](#MVC_패턴_해리&션)
4. [Springboot autoConfiguration - 러너덕](#Springboot_autoConfiguration_러너덕)
5. [캐시 - 큰곰](#캐시_큰곰)
6. [시간복잡도 - 제이](#시간복잡도_제이)
7. [JPA와 JDBC - 올레](#JPA와_JDBC_올레)
8. [Git branches - 안돌](#Git_branches_안돌)
9. [RESTful - 이지](#RESTful_이지)
10. [함수형 프로그래밍 - 도넛](#함수형_프로그래밍_도넛)
11. [인증과 인가 - 루피](#인증과_인가_루피)
12. [Spring vs Spring Boot - 닉](#Spring_vs_Spring_Boot_닉)
13. [웹서버 vs WAS - 희봉](#웹서버_vs_WAS_희봉)
14. [빌드용어 - 에헴](#빌드용어_에헴)
15. [INDEX - 안돌](#INDEX_안돌)
16. [TCP UDP - 르윈](#TCP_UDP_르윈)
17. [API vs Library vs Framework - 티버](#API_vs_Library_vs_Framework_티버)
18. [Hash Function - 코니](#Hash_Function_코니)
19. [요청 응답 흐름 과정 - 철시](#요청_응답_흐름_과정_철시)
20. [Process & Thread - 김고래](#Process_&_Thread_김고래)
21. [Interrupt와 Context Switching - 코맥](#Interrupt와_Context_Switching_코맥)
22. [Servlet & Spring - 규동](#Servlet_&_Spring_규동)
23. [MVC - 제이엠](#MVC_제이엠)
24. [Connection Pool & Keep-Alive - 쿠기](#Connection_Pool_&_Keep-Alive_쿠기)
25. [Forward Proxy vs Reverse Proxy - 쉐이크반](#Forward_Proxy_vs_Reverse_Proxy_쉐이크반)
26. [TLS - 에단](#TLS_에단)
27. [Latency & Bandwidth - 효오](#Latency_&_Bandwidth_효오)
28. [HTTP 2.0 - 아이크](#HTTP_2.0_아이크)
29. [JVM의 Garbage Collector - 던](#JVM의_Garbage_Collector_던)
30. [Apache MPM vs NGINX vs Node.js - 미스터코](#Apache_MPM_vs_NGINX_vs_Node.js_미스터코)
31. [Web polling vs Web push - 유니](#Web_polling_vs_Web_push_유니)
32. [JVM Stack & Heap - 무민](#JVM_Stack_&_Heap_무민)
33. [CORS - 코나스](#CORS_코나스)
34. [scale up vs scale out, SPOF - 포도당](#scale_up_vs_scale_out,SPOF_포도당)
35. [트랜잭션 메커니즘 - 에이든](#트랜잭션_메커니즘_에이든)
36. [DB Optimizer - 버디](#DB_Optimizer_버디)
37. [SQL 인젝션 - 로비](#SQL_인젝션_로비)
38. [Clustered vs Non-clustered Index - 올라프](#Clustered_vs_Non-clustered_Index_올라프)
39. [Sharding, Clustering, Replication - 히브리](#Sharding,Clustering,Replication_히브리)
40. [JDK Dynamic Proxy vs CGLIB Proxy - 미르](#JDK_Dynamic_Proxy_vs_CGLIB_Proxy_미르)
41. [AOP - Advice, Target, Pointcut - 뚱이](#AOP_Advice,Target,Pointcut_뚱이)
42. [Sticky session & Session Clustering - 마틴](#Sticky_session_&_Session_Clustering_마틴)



---

## 1. [OCP와 전략패턴 - 베디](https://www.youtube.com/watch?v=90ZDvHl8ROE&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=2)<a name = "OCP와_전략패턴_베디"></a>

### if-else의 문제점

1. 코드 복잡: 변경 확장이 될수록 코드가 복잡해진다. 이에 따라 코드를 수정하거나 수정할 위치를 찾는데 점점 오래 걸린다.

2. 누락 사고: 실수로 추가하지 않고 누락하는 부분이 생길 수 있다.

#### 코드복잡

코드가 복잡해질수록 유지보수가 점점 어려워진다. if 안에 들어가는 블록이 작을 땐 문제가 없다.

하지만 기능 추가에 따라 복잡도가 증가하면서, 추가 수정이 어렵다.

#### 누락사고

여러 부분을 수정해야하는데 일부 부분에만 반영하고, 일부는 깜빡하고 반영을 안할 수 있음.



### 개방폐쇄원칙

위 문제를 개선하기 위해 개방폐쇄원칙 적용하자.

개방폐쇄원칙: 소프트웨어 구성요소(컴포넌트, 클래스, 모듈, 함수)는 확장에 개방돼야 하지만, 변경에 대해서는 폐쇄돼어야 한다.

기존의 코드를 변경하지 않으면서 기능을 추가할 수 있어야 한다는 뜻이다. 중요한 건 변경에 폐쇄돼야 한다는 것이다. 기능변경할때마다 기존 코드가 바뀌면 확장 때마다 힘들기 때문이다. 예를 들어, if else문에서 로직이 추가될 때마다 else if가 추가(변경)된다.

#### 개방폐쇄원칙을 적용하는 방법

1. 상속
2. 컴포지션

**상속**은 상위, 하위 클래스가 강력히 결속돼있기에 상속이 바뀌면 하위도 바뀌게 된다. 이런 걸 깨지기 쉬운 상위 클래스 문제라고 한다.

**컴포지션**은 변경될 것과 변하지 않을 것을 엄격히 구분하는 것이다. 그리고 구분된 것들이 만나는 지점에 인터페이스 정의한다. 구현에 의존하기보다 인터페이스에 의존하게 하는 것이 핵심이다. 예제에서는 if-else부분을 인터페이스화 할 수 있다. 이렇게 되면 기존 코드 변경없이, 인터페이스를 새로 구현하면 확장 가능하다. 이렇게 인터페이스화하면 테스트도 쉬워진다.

#### 전략패턴

개방폐쇄원칙을 지키기 위해 인터페이스화하는 것이 전략패턴이다. 즉, 전략패턴은 기존의 코드 변경없이 행위를 자유롭게 바꿀 수 있게 해주는 디자인패턴이다.

전략은 어떤 목적을 달성하기 위해 일을 수행하는 방식이다. 예를 들어, 비즈니스 규칙이나 문제를 해결하는 알고리즘 등이 있다.

전략패턴은 전략을 쉽게 바꿀 수 있는 디자인패턴이다. 행위를 클래스로 캡슐화해 동적으로 행위를 자유롭게 바꿀 수 있게 해준다. 전략패턴은 새로운 기능의 추가가 기존에 코드에 영향을 미치지 않게 하므로 개방폐쇄원칙을 준수한다.

#### 전략패턴의 구성요소

context는 전략패턴을 이용하는 역할을 수행한다. 필요에 따라 동적으로 구체적인 전략을 바꿀 수 있도록 한다.

strategy는 인터페이스나 추상클래스로 외부에서 동일한 방식으로 알고리즘을 호출하는 방식을 명시한다.

concreteStrategy는 전략패턴에서 명시한 알고리즘을 쉽게 구현한 클래스이다.

#### 템플릿 메소드 패턴 vs 전략패턴

공통점은 둘 다 목적이 개방폐쇄원칙을 지키기 위함이다.

차이점은 구현 방법이다. 전략패턴은 컴포지션을 활용하는 반면,  템플릿메소드패턴은 상속을 활용한다.



---

## 2. [DTO vs VO - 지노&비모](https://www.youtube.com/watch?v=EeJnNaiMy3U&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=4)<a name = "DTO_VS_VO_지노&비모">

**DTO(Data Transfer Object)는** 레이어 간 데이를 전달하는 객체이다. 예를 들어 시험본 게 채점되려면, omr카드로 데이터를 전달해줘야 하는데, 여기서 omr카드가 DTO라고 볼 수 있다. DTO는 세터, 게터로 이뤄진다. DTO의 특징은 데이터 접근 메소드 외 기능을 가지지 않는다는 것이다(정렬, 직렬화 등 데이터 표현을 위한 기능은 가질 수 있음). 또한 데이터의 캡슐화를 통해 유연한 대응이 가능하다는 것이다(덕분에 데이터 요청 수를 감소시키는 효과가 있다).

**VO(Value Object)는** 값을 가지는 객체이다. VO의 특징은 값 자체로 의미를 가진다는 것이다. 또한 변하지 않는 값을 가진다는 것이다. 값이 변하지 않음을 보장하여 코드의 안정성과 생산성을 높인다. 그리고 VO는 (DTO와 달리) 값이 같다면 동일한 객체로 판단한다. 즉, 각 객체를 비교하는 데 사용되는 id가 없다. 같은 객체인지 판단하기 위해 각 속성들의 값을 비교한다.

**DTO와 VO의 공통점은** 레이어 간 전달할 때 사용 가능하다는 것이다. VO도 불변을 보장하기 때문에 데이터 전달 용도로 사용 가능하다.

**DTO와 VO의 차이점은**, DTO는 값이 변할 수 있고, VO는 값이 변하지 않는다는 것이다. 또한, DTO는 레이어 사이에서만 사용 가능하고, VO는 레이어 사이 뿐 아니라 레이어 내부에서도 사용 가능하다. DTO는 값만으로 판단하지 않고(같은 값을 가져도 다른 객체일 수 있다), VO는 값만으로 판단한다(같은 값을 가지면 같은 객체이다). DTO는 데이터 접근 이외 기능을 가지지 않고, vo는 비즈니스 로직을 가질 수 있다.



---

## 3. [MVC 패턴 - 해리&션](https://www.youtube.com/watch?v=uoVNJkyXX0I&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=5)<a name = "MVC_패턴_해리&션">

디자인패턴은 sw개발방법을 공식화한 것이다.

MVC 패턴은 어플리케이션을 모델, 뷰, 컨트롤러 3가지 역할로 구분한 디자인패턴이다.

디자인 패턴 중 하나인 jsp + java bean의 장점은 구조가 단순하다는 것이다. 단점은 출력과 로직 코드가 섞여, jsp코드가 복잡해진다는 것이다. 프론트가 백엔드가 혼재되어 분업이 용이하지 않다. 유지보수가 어렵다.

디자인 패턴 중 하나인 java bean(모델) + jsp(뷰) + 서블릿(컨트롤러)의 장점은 뷰와 로직의 분리로 위보다 덜 복잡하고, 분업이 용이하고 요지보수 쉽다는 것이다. 단점은 위보다 학습이 필요하고 작업량이 많다는 것이다. 

MVC 패턴의 흐름은 유저 -> 어플리케이션 -> 컨트롤러 -> 모델(비즈니스 로직 수행) -> 뷰(화면 보여줌)이다. 모델은 값과 기능을 가지는 객체이다. 비즈니스 로직 수행한다. 뷰는 모델에 포함된 데이터 시각화한다. 컨트롤러는 모델 객체로의 데이터 흐름을 제어한다. MVC패턴은 뷰와 모델의 역할 분리했다는 것이 중요하다.

MVC패턴의 장점은 각 컴포넌트 간 코드 결합도를 낮출 수 있다는 것이다. 또한 코드 재사용성을 높일 수 있다. 구현자들 간 커뮤니케이션 효율성을 높일 수 있다.

MVC패턴에서 자주하는 실수는 모델에서 뷰에 접근하거나 뷰의 역할을 수행하는 것이다. 또는 뷰에서 과한 값 검증을 하거나 예외처리를 해버리거나, 뷰에서 비즈니스 로직을 수행하는 것이다.

컨트롤러는 가능한 한 로직은 없이, 객체 간 연결을 해주는 역할을 수행한다. 그런데 컨트롤러에서 중복이 발생하면 별도의 객체, 별도의 메소드로 분리. 이 때 일반적으로 서비스를 사용한다. 서비스는 비즈니스로직을 수행하는 메소드를 가진 객체이다. 한편, 리포지토리는 데이터 엑세스 메소드를 구현한다.



---

## 4. [Springboot autoConfiguration - 러너덕](https://www.youtube.com/watch?v=OXILjfY8edw&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=7)<a name = "Springboot_autoConfiguration_러너덕">

어노테이션은 그 자체로 기능을 수행하지 않고, 마킹을 하는 것 뿐이다. 어노테이션을 처리해주는 함수가 따로 있다. 그 함수가 어노테이션을 읽어들여, 필요한 처리를 한다. 어노테이션의 활용 순서는 어노테이션 선언 -> 어떻게 처리할 지 작성 -> 어노테이션이 필요한 곳에 붙이기 이다. 코드 사이사이 분산된 걸 한 군데 모아서 처리하고 싶을 때 어노테이션으로 처리하면 효과적이다.

@SpringbootApplication도 어노테이션이다. 이 어노테이션을 처리하는 뭔가가 있을 것이다. 그런데 @SringbootApplication 어노테이션에도 여러 어노테이션이 붙어있다. 이 어노테이션들 덕분에 톰캣이 뜨고 의존성 주입이되는 등 프레임워크가 작동하게된다.

autoConfiguration은 톰캣을 띄우는 등을 수행한다. springboot autoconfigure jar파일에 meta-inf/spring.factories에서 enableconfigure를 키로하는 외부 의존성들이 나열돼있다. 외부의존성을 enableautuconfigure가 쭉 체크하면서 자동으로 가지고 온다. 선언돼있다고 다 가져오는 건 아니고, 조건에 따라(아직 주입이 안돼있다던지...) 가져온다.



---

## 5. [캐시 - 큰곰](https://www.youtube.com/watch?v=c33ojJ7kE7M&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=8)<a name = "캐시_큰곰">

### 사전지식

#### 1. 메모리 계층구조

컴퓨터의 메모리에 있어서 속도, 용량은 반비례 관계이다. 둘 다 잡기에는 비용이 너무 많이 든다. 그래서 데이터 저장공간은 상황에 따라 속도를 선택할 지, 용량을 선택할 지 정해 역할을 나눈다. 데이터 저장공간을 속도 - 용량 순서대로 쌓으면 마치 피라이드와 같은 형상이 된다. registers - cache - memory - disk.

#### 2. 파레토의 법칙

상위 20%가 전체 결과의 80%를 만든다는 법칙이다. 자주 쓰는 20%를 빠른 디스크가 담당하게 하면 효율적이다.



### 데이터 지역성의 원리

자주 쓰이는 데이터는 시간적, 공간적으로 한 곳에 몰려있을 가능성이 높다.

**시간지역성**은 예를 들어, 포문에서 변수 하나 선언하면 그 포문 끝날 때까지 해당 변수는 계속 쓰일 가능성이 높다는 것이다. 포문이 끝날 때까지 그 변수를 쓰니까 말이다. **공간지역성**은 예를 들어, 포문에서 어떤 배열에 접근한다면 포문 끝날 때까지 그 배열의 공간을 쓸 가능성이 높다는 것이다. 실행시간에 따른 메모리 주소를 시각화해서 보면 시간적으로, 공간적으로, 순차적으로 뭉쳐있는 걸 볼 수 있다. 

공간지역성 예제: 창고에 종이가 많고, 일부를 내 자리에 가져와서 일처리(도장찍기)를 하고 다시 가져다 놔야하는 경우를 가정하자. 이 때 창고에 있는 모든 종이를 일단 자리에 가져와놓고 일하면 효율적일 것이다.



### 캐시

캐시는 나중에 필요할 수도 있는 무언가를 신속하게 회수할 수 있는 보관장소에 저장하는데, 이 공간을 캐시라고 한다. 저장된 것은 어떤식으로든 보호되거나 숨겨진다.

#### 캐시의 작동방식

자주 쓰는 원본 데이터를 빠르게 접근할 수 있도록 어떤 공간을 만들어놓는 것이다. 즉 원본 데이터에 접근하는것보다 훨씬 빠르게 저장하는 것이다. 그러기 위해서는 자료구조가 필요할텐데, 자바에서는 해시맵 등이 있다.

데이터가 필요할 때 원본데이터가 있는 곳을 접근하기 전 캐시 내부부터 찾는다. 찾지 못하거나 너무 오래된 데이터면 그 때 원본데이터에 접근한다. 원본 데이터를 가져올 때 캐시를 갱신한다. 캐시 공간은 작으므로 공간이 모자르게 되면 안 쓰는 데이터부터 삭제하여 공간을 확보한다.

#### 캐시의 활용도

캐시는 여러 곳에서 사용된다. 현재 cpu 엄청 빨라서 일반적으로 아무리 빠른 기억장치라도 cpu를 못따라간다. 그래서 캐시메모리가 있어 성능을 좋게 하려고 한다. 게임같이 실시간성이 필요한 곳에 캐시가 활용되도 한다. 하드디스크는 cpu보다 훨씬 느린 장치이기 때문에 캐시를 두어 속도를 올리는 노력이 있다. jpa도 캐시 사용한다. jpa의 영속성 컨텍스트가 캐시의 일종이다. 유튜브에서 활용한다. 메인 서버는 미국에 있는데 한국과 미국을 잇는 인터넷 회선은 비싸고 용량을 늘리기도 어렵다. 그래서 구글은 각 통신사에 구글 글로벌 캐시를 둔다. 인기있는 동영상은 미국 서버까지 올 필요없이 국내 서버에서 처리하도록 한다. 이런 식으로 세계 각지에 캐시 서버를 두어 전송 속도를 높이고 부하를 분산하는 시스템을 CDN이라고 한다.

##### 웹 캐시 

네트워크를 통해 데이터를 가져오는 건 하드디스크보다 느릴 때가 많다. 그래서 웹브라우저는 웹페이지를 가져올 때 캐시를 적극사용한다. html, css, js 이미지 파일들을 캐시에 둬서 재요청 받을 때 같은 파일은 재활용하도록 돼있다.

##### 웹서버

웹서버도 비슷한 요청을 받는 경우가 많다. 서버에서 생성한(아마도 was인 듯) html을 캐싱해뒀다가 다음 번 요청에 이를 재활용한다(응답 캐시).

##### 클라이언트

클라이언트도 자주 요청받는 내용은 웹 서버로 전달하지 않고 웹 서버 앞단의 프록시 서버에서 캐싱해둔 데이터를 제공(프록시 캐시)한다.

##### 브라우저 캐시

브라우저 캐시는 웹 프로그래머가 통제해야한다. 웹서버에서 클라이언트에 보내는 http 헤더에 캐시 지시자를 삽입하면 클라이언트 웹 브라우저에 해당 지시자에 명시된 캐시 정책에 따라 캐싱한다. 정책의 예를 들면, 이 파일은 캐싱을 언제까지 해야한다, 이 파일은 캐싱하면 안된다 등이 있다. 캐시의 유효시간이 지나도 캐시된 데이터가 바뀌지 않은 경우를 확인하기 위해 ETag(유효성 검사 토큰)라는 걸 사용하기도 한다. 캐시 유효시간을 길게 잡았는데 그 사이에 웹페이지를 수정할 수 있다. 근데 웹브라우저는 캐싱돼있으니 옛날 데이터를 보여준다. 이럴 때를 대비해 리소스(css 등)의 파일이름에 버전 정보를 준다. http헤더에 파일 이름이 달라질 때, 캐싱 무효화가 되기 때문에 파일 이름의 버전정보를 업데이트하면, 캐시 유효기간이 길어도 변경사항이 생겼을 때 반영가능하다. 브라우저 캐시는 파일별로 정책이 달라야하는데 이건 프로그래머가 익혀야한다. 예를 들어, 정적 파일과 동적 파일은 정책이 다르다. 비공개 정보가 들어 있는 파일은 캐싱을 막아야 할수도 있다.

##### Redis

웹에서 캐싱할 때 많이 쓴다. 특징은 모든 데이터를 메모리에 올려서 처리한다는 것이다. 따라서 속도가 빠르다. redis의 약자 중 dictionary는 해시테이블(자바의 해시맵과 비슷)이라고 생각하면 된다. 메모리에 다 넣었으므로 재부팅 시 데이터가 날아가지 않도록 하드디스크에 저장한다는 특징도 있다. 캐싱에 많이 쓰이긴 하지만, db이기때문에 데이터가 남는다는 특징도 있다.

##### EHcache

자바 표준 캐싱 api이다. sp ring, 하이버네이트 등에서 사용 가능하다.



캐시는 어디에나 있다. 웹 서비스의 모든 단계에 들어간다. db에도 들어가고, 하드디스크에도 들어가고...



---

## 6. [시간복잡도 - 제이](https://www.youtube.com/watch?v=IEH3YA2Nn4Q&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=9)<a name = "시간복잡도_제이">

알고리즘은 문제를 해결하는 방법이다. 배우자 선택 알고리즘 예시로 들자. 건너뛰기 혹은 살펴보기 전략이 있다.

0명 살펴보기: 살펴보지 않고 나온애 그냥 선택하겠다. 성공 확률이 30퍼 정도.

1명 살펴보기: 처음 만난 사람을 무조건 거른다. 두번째부터 처음 애보다 낫다 싶으면 선택한다. 성공확률이  50퍼정도.

상황별로 몇명 살펴보기를 하는게 좋을 지 다르다. n명 살펴볼 때 n이 커질수록 성공확률이 37%에 수렴한다. 예를 들어, 100명 만날거면 37명은 일단 만나고 다 거름. 38번째부터 37명보다 괜찮은 사람 나오면 바로 선택. 그 때 성공확률이 37퍼.



### 시간복잡도

문제를 해결하는 데 걸리는 시간과 입력의 함수관계이다. 시간복잡도를 계산하는 데 중요한 건 핵심이 되는 연산을 찾는 것이다. 알고리즘을 평가할 때 보통 최악을 생각한다. 그 이유는 최선의 경우는 어떤 알고리즘을 쓰든 다 만족할만한 결과이기 때문에(다 엄청 빠름. 다 비교할 수 없을만큼 비슷하게 빠름) 비교할 수가 없다는 것이다. 평균으로 하는 것도 힘든게, 평균적인 기준을 정의하기 어렵다.



### 현실적 알고리즘 vs 비현실적 알고리즘

현실적 알고리즘(polynomial complexity): 다항 시간에 풀리는 알고리즘. 상식 선에서 풀리는 거라고 생각해도 좋다.

비현실적알고리즘(nondeterministic polynomial complexity): 복잡도가 팩토리얼, 지수형태로 나옴. 예: 해밀턴 경로 문제. 풀 수가 없다. 현재 p인지 np인지 증명할 수 없다(?). 예를 들어, 공개키 암호키 알고리즘은 np라고 알려져있지만, p일 수도 있다. 13층이라는 영화 추천.



---

## 7. [JPA와 JDBC - 올레](https://www.youtube.com/watch?v=Ppqc3qN75EE&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=10)<a name = "JPA와_JDBC_올레">

jdbc 시절, 테이블 생성하고 커넥션 설정(커넥션 객체를 수동으로 열고 닫아야 했음)하고, 데이터삽입(쿼리를 먼저 만들어야 함)해야 했다.

과제를 통해 알아본 jdbc의 특징은

1. sql문을 잘 알아야 한다.
2. connection 관리(열고 닫기) 해야한다.
3. preparedStatement, resultset 활용한다.

=> connection 객체가 db와 app 연결을 관리하고, preparedStatement가 sql을 전달하며, resultset객체를 통해 결과값을 전달한다.

jdbc를 중국에서 금 가져오는걸로 설명하자면,

1. 중국어를 알아야 하니 번역기 필요하다.
2. 도로 필요하다.
3. 자동차에 조건을 넣어서, 금광으로 보내고, 자동차가 결과를 가져온다.
4. 이렇게 되면(번역기 있고, 도로 깔려있고, 자동차만있으면) 중국어 몰라도(데이터베이스의 고유한 특성과 상관없이) 금을 가져올 수 있다.

jpa를 적용하면, 이전에 자바 app - jdbc - db 이렇게 연결돼있었는데, 자바 app - jpa - jdbc - db 이렇게 바뀐다. 즉 sql을 많이 고려하지 않아도 app단에서 데이터 접근할 수 있게 도와준다. jpa장점은 sql 잘 몰라도 된다는 것이고, jpa단점은 쿼리가 이상해질 수 있다는 것이다



---

## 8. [Git branches - 안돌](https://www.youtube.com/watch?v=MIGliPrUMGE&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=11)<a name = "Git_branches_안돌">

### 깃을 쓰는 이유

1. 버전컨트롤
2. 코워킹 툴
3. 강력한 브랜치: 관심사 분리. 다른 버전컨트롤 툴에 비해 브랜치 기능이 강하다. 브랜치를 넘나들 때 시간이 얼마 안걸린다.



### 깃 오버뷰

커밋은 일반적인 일처리 방식과 달리, 부분적으로 일할 수 있게 한다. 커밋은 완전한 상태를 가지고 있지 않다고 생각할 수 있다. 맥락과 합쳐졌을 때 커밋이 의미를 가진다. 머지를 하려면 공통의 부분(common parent)이 있어야 한다.

#### 머지 & 리베이스

머지 시 각 브랜치를 부모로하는 커밋이 생긴다. 머지와 다르게, 새로운 커밋을 만들지 않고 커밋들을 연결하는 방법이 리베이스이다. 머지는 이전 브랜치들에 아무 변화가 없다. 리베이스는 어떤 커밋들의 부모 커밋이 달라지게 된다. 리베이스를 통해 커밋을 선형적으로 만들 수 있는 건 장점(누가 봐도 이해하기 쉬움)이고 리베이스를 통해 원래 커밋 구조에 변화가 생긴다는 건 단점이다. 머지와 리베이스 호불호가 갈린다.

#### 컨플릭트

컨플릭트는 공통된 걸 각 브랜치에서 수정했을 때 생긴다. 컨플릭트 해결방법으로 추천하는 건 revert를 쓰는 것이다. 

##### 언제 컨플릭트가 잘 나냐면...



##### branching strategy

git flow 에서 develop 브랜치를 두는 이유는 이 흐름을 따르면 효율이 생기고 정리되는 느낌이 생기기 때문이다. 디벨롭에서 하다가 장애가 났을 때 마스터에서 새 브랜치 파서 문제 수정 후 디벨롭으로 돌아와야 하는데, 디벨롭 문제 없으면 릴리즈에서 테스트 해보고, 마스터로 올리는 등의 흐름을 따른다.

##### 프로젝트 중 컨플릭트가 생기는 주요 이유

sqash commit은 pr 어프루브 시 커밋들 다 합쳐서 하나로 만든다. 머지할 땐 스쿼시 커밋을 했는데, 내가 그 커밋을 안받으니까 스쿼시 된 부분이랑 스쿼시 안된 부분이랑 컨플릭트(다름)이 뜬다. 스쿼시 커밋 후에는, 그 스쿼시 커밋을 받아와야 한다.

자주 쓰는 깃 명령어도 알려주심.



## 9. [RESTful - 이지](https://www.youtube.com/watch?v=xY7cpMuWh4w&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=12)<a name = "RESTful_이지">

REST의 RE는 표현, S는 상태, T는 전달을 의미한다. 자원의 표현을 가지고 상태 전달한다.

자원의 표현 = HTTP uri

상태 전달 = HTTP Method

restful은 rest란 아키텍쳐 스타일의 제약조건을 모두 만족하는 시스템을 말한다.

rest아키텍처의 제약조건

1. client - server
2. stateless
3. cache
4. uniform interface
5. layered system
6. code-on-demand(option)

Richardson Maturity Model은 rest의 핵심 요소를 세 단계로 나눈다.

level0은 http를 rpc를 기반으로 한 원격통신을 위한 터너링 메커니즘으로 사용된다. rpc는 별도의 원격 제어를 위한 코딩 없이 다른 주소 공간에서 함수나 프로시저를 실행할 수 있게하는 프로세스 간 통신기술이다. 즉 클라이언트가 서버의 프로그램을 실행하기 위해 사용하는 통신기술.이다 xml을 활용해 데이터를 주고받는다.



### Richardson Maturity Model level 0

1. client - server:

   클라이언트가 서버에게 요청하고 서버가 클라이언트에게 응답하는 구조이다.

2. 클라이언트와 서버의 통신에는 상태가 없어야한다. 모든 요청은 필요한 모든 정보를 담고 있어야 한다.

3. Layered System:

   계층으로 구성이 가능해야한다. 서버는 다중 계층으로 구성될 수 있다. 순수 비즈니스 로직을 수행하는 서버, 사용자 인증, 암호화(ssl), 로드밸런싱 등을 하는 계층을 추가하거나 프록시, 게이트웨이같은 중간 매체를 사용 가능하다. 이것들을 사용해도 클라이언트는 모른다.

4. Uniform Interface

   representation의 형태는 html, xml, json 등 content-type으로 결정된다.

### Richardson Maturity Model level 1

5. 리소스 개념이 도입된다. 모든 요청을 단일 서비스 엔드포인트로 보내는 것이 아니라 개별 리소스와 통신한다. identification of resources은 자원이  유일하게 식별 가능해야 한다는 것이다. 리소스가 하나 이상의 유일한 특정 주소인 uri로 식별돼야한다. 아직 post 메소드로만 요청을 하기 때문에 uri나 바디로 어떤 동작을 할 지 알려줘야 한다.

### Richardson Maturity Model level 2

6. http methods : get, put, delete등 post외 다른 메소드 사용 가능하다. level 0,1보다 http의 사용법에 가능한 가깝게 사용한다. 

7. manipulation of resources through representation : http 메소드로 표현(crud)를 담아야 한다. 안전한 오퍼레이션과 안전하지 않은 오퍼레이션 간의 강한 분리를 제공해야한다. 같은 요청을 여러번 해도 결과가 동일하다거나, 자원을 변경하지 않게 할 수 있다. 

8. self-descriptive message : 메세지는 스스로를 설명해야한다. 그러기 위해 http method, status code, header등을 활용한다.

9. cache : get함수는 상태를 변화시키지 않기 때문에 캐싱 가능하다.

### Richardson Maturity Model level 3

10. hateoas 도입: 클라이언트가 전적으로 서버와 동적인 상호작용 가능하게 한다. 클라이언트가 서버에 요청을 보낼 때 요청에 필요한 uri를 응답에 포함시킨다. 이것의 장점은 요청 uri가 변경돼도 클라이언트에서 동적으로 생성한 uri를 사용함으로써 클라이언트가 uri 수정에 따라 코드를 변경하지 않아도 된다는 것이다.

11. code-on-demand: 서버가 네트워크를 통해 클라이언트에 프로그램을 전달하면 그 프로그램이 클라이언트에서 실행될 수 있어야 한다.

### 정리

1. rest는 소프트웨어 아키텍처의 한 형식이다.

2. rest아키텍처는 여러 개의 제약조건을 가지고 있다.

3. restful은 제약조건들을 모두 만족해야 한다.

4. http method, status code 를 용도에 맞게 써야하고, http 헤더와 link를 신경쓰면 restful 서비스를 설계할 수 있다.



---

## 10. [함수형 프로그래밍 - 도넛](https://www.youtube.com/watch?v=ii5hnSCE6No&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=13)<a name = "함수형_프로그래밍_도넛"></a>

역사를 설명해주셨지만 무슨말인지 잘 이해못함... 

### 함수형 프로그래밍이란 무엇인가?

하나의 프로그램을 수학 함수의 합성체로 보는 관점이다. 함수형 프로그래밍의 철학을 담은 자바스크립트나 루비온레일즈가 재조명받고있다.

### 함수형 프로그래밍의 요소들

1~4가 핵심이고, 5~7이 부수적이다.

1. 고계함수

2. 일급함수

3. 커링과 부분적용

4. 재귀와 꼬리 재귀 최적화

5. 멱등성

6. 순수 함수와 참조 투명성

7. 불변성과 영속적 자료구조. 메모이제이션.



#### 3. 커링과 부분 적용

꼬리 재귀는 자기 자신만 부르는 재귀함수이다. 여기선 스택오버플로우가 안난다.

#### 5. 멱등성

같은 입력에 대해 같은 출력이 나온다는 것이다. 영속성 자료구조 - 값을 바꿀 필요가 있을 때 새로 만들면 큰 비용이 발생할거라고 생각하지만, 꼭 값을 항상 다 복사할 필요는 없다(?). 바뀌지 않는 것들끼리 연결하면 된다.



### 왜 함수형 프로그래밍인가?

1. 높은 표현력을 통해 불필요한 코드를 줄일 수 있다.
2. 함수형 프로그래밍 언어군은 프로그래밍 언어론의 최신 연구 결과를 반영하고 있다.

함수형이 아니게 짤 때는 "무엇을"에 집중하기보다는 "어떻게"에 집중하고 있지만, 함수형일 땐 "무엇"을 하는 지 명확히 알 수 있다. 함수형 프로그래밍에서는 함수형으로 쓸 수도 있지만, 함수형이 아니어도 쓰는 기법들이 있다. 함수형은 산업보다도 연구목적이 있다. 그래서 새로운 것들이 많이 반영돼있다. 멀티쓰레딩에서 락을 거는건 부정적으로 못하게하는거고, 긍정적인 관점인 트랜잭셔널 메모리는 일단 하고 하면 안되는거면 롤백시킨다. 함수형이랑 큰 관련이 없을 수 있지만, 최신 트렌드(?)를 반영했다고 할 수 있다. 함수형 프로그래밍의 타입클래스는 자바 인터페이스가 좋아진 느낌이다. 

함수형 프로그래밍에서 사용되는 대수적 자료형은 다른 자료형의 값으로 구성된 자료형을 말한다. 곱타입(class, struct)에서는 여러 값이 내부에 동시에 존재한다. 합타입(enum, union)에서는 한 번에 한 값이 존재한다. 이넘과 다른 점은 상수 뿐 아니라 변수도 넣을 수 있다는 것이다.



### 패턴 매칭

if, switch보다 발전한 거다. 자료형의 구조를 뜯어볼 수 있다.



### 대표적 함수형 프로그래밍 언어

1. lisp계열

2. ml계열

3. scala

4. erlang

5. haskell: 함수형 프로그래밍 언어의 대표. 타입클래스, 모나드, 소프트웨어 트랜잭셔널 메모리 등 최초 도입. 학술위원회에서 설계된 언어.

하스켈은 어려워운데 왜냐면 극단적 설계 때문이다.

1.  사실상 유일한 순수 함수형 언어.
2. 엄격한 정적 타이핑
3. 유일하게 지연평가정책을 디폴트로 채택.



### java 타입 체계의 문제점

제네릭의 T를 예시로 보자면, T가 똑같은 타입인 게 보장이 안된다. null이 막 돌아다니는 것도 문제다. string이 들어온다고 적어놓고, null이 들어올 수도 있고, exception이 뜰 수도 있다. 엄밀히 말하면 이상한 것이다. 반면 함수형에서는 타입의 순수함이 보장된다.



### 모나드

모나드란 자기함자 범주의 모노이드일 뿐이다(?). 

범주론 : 범주는 수학적 구조를 가진 대상과 그 대상들 사이에서 사상을 다룬다(관계에 집중한다는 것이, 집합이 요소에 집중하는 것과 차이점이 있다).

결국, 모나드는 카테고리화 하려고 나온거다(?). 

모나드는 함자의 일부이다. 함자는 한 범주의 대상과 사상을 다른 범주로 대응하는 함수이다. 예를 들어, 내가 가진 어떤 관계를 다른 쪽으로 매핑하는 것이다. stream, optional의 map이 바로 함자 연산이다.

그런데 함자에 문제점이 있다. 함자가 중첩된다면 정상적인 합성이 불가능해진다(널지옥). 그거 안하려고 optional을 쓰면 opthinal지옥에 빠진다. 그래서 모노이드가 필요함. 항등식의 개념이 연장하여(?), 모노이달 카테고리를 만들 수 있다. 덕분에 연산을 줄일 수 있다. 연산을 줄이는 join(flat)과 map을 합친 걸 bind(flatmap)라고 하는데, 이걸 쓰면 함수의 합성이 용이해진다. 덕분에 optional 지옥에 빠지지 않고, optional을 하나로 유지할 수 있다. 

**모나드 결론: 이걸 쓰면 이것저것 생각할 필요 없이, 그냥 결과로 나오는 타입을 잘 맞춰 쓰면 된다.**



### 자바에 함수형 프로그래밍 적용

1. 람다를 쓸 때 내부 변수는 불변하는 제약이 있다. 하지만 배열을 쓰면 회피 가능하다.

2. 람다 내에서 체크예외가 뿜어져 나올 때, 트라이캐치 써야한다. 그거 쓰기 싫기 때문에 Exception을 던지는 FunctionalInterface를 직접 정의하여 회피 가능하다.

3. 커리 함수를 만들면 어느 함수나 커링 가능(?)하다.

4. 스트림은 실질적으로 리스트와 동일하나, 지연 평가를 적용하여 무한의 개념을 이용할 수 있다 - 그냥 쓰면 된다.

5. CompletedFuture : 퓨처는 소비자api로, 특정 시점에 값이 도달했는 지 알 수 있고, 도달했으면 값을 알 수 있다. 프로미스는 생산자api로, 아직 완료되지 않은 계산을 임의로 중지할 수 있다. 또한 특정한 값을 임의로 반환할 수 있다. CompletedFutrue는 프로미스다. 싱글스레드여서 레이스컨디션 자체가 존재하지 않는 자바스크립트에서는 프로미스가 굉장히 유용한 것과 달리, 자바에서는 공유 상태에 잘못 접근하면 위험할 수 있다.

6. Optional : optional은 값이 존재하거나 존재하지 않음을 나타내는데, 이를 Exception 대신 쓸 수 있다. Exception의 종류를 알아야 하는 경우 Either(Result) 타입을 쓸 수 있으나 자바에는 없다. 일반적으로 생성자에서 Optional을 통헤 널 체크 및 추가적인 validation을 하여 exception을 발생시킬 수 있다. 하지만 Exception을 발생시키지 않고 팩토리 메소드를 통해 Optional 타입으로 반환할 수도 있다. 반환 타입이 일정하므로 예외 처리 없이 일관성있게 코드를 짤 수 있다. 단, 모든 예외 처리를 Optional로 처리하는 건 좋지 않다. 가령, 0으로 나눌 때 생기는 ArithmeticException을 발생시키지 않기 위해 Optional을 쓸 경우, if문으로 0을 분기처리하는 것 이상의 비용이 든다. Exception을 쓰지 않으려는 것은 타입 안정성을 추구하겠다는 것이다. Optional에서 내부의 값이 존재하는 경우, map으로 타입을 바꿀 때 반드시 원래값과 관련이 있을 필요는 없으므로 편견을 깨면 자유로워진다.



## 11. [인증과 인가 - 루피](https://www.youtube.com/watch?v=JZgD8aPkHSc&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=14)<a name = "인증과_인가_루피"></a>

회원가입은 나의 정보를 등록하는 것이다. 로그인은 내가 누구인 지 입증하는 것이다.

**인증(authentication)은** 등록된 유저의 신원을 입증(validate)하는 것이다. 보호된 리소스에 접근하는 것을 허용하기 이전에 등록된 유저의 신원을 입증하는 것이다. 접근하는 것을 허용하기 이전에 수행된다.

**인가(authorization)는** 인증된(요청된 리소스에 접근할 수 있는 권한이 있는) 유저인지 입증(validate)하는 것이다. 인증 후에 수행된다. 즉 인증되었지만 인가되지 않을 수 있고, 인가되었지만 인증은 되지 않았다는 건 불가능하다. 



### 웹에서의 인증/인가

1. 요청 헤더

2. 세션, 쿠키

3. 토큰

4. Oauth



### Oauth

다른 웹사이트 상에 있는 내 정보에 대해 접근 권한을 부여하는 공통적인 수단이다. 구글로그인, 페이스북로그인 등이 사용하는 인증절차가 Oauth의 예이다.

#### Oauth의 흐름

##### Oauth인증

1. 유저가 브라우저에서 로그인 버튼 누르면 Oauth제공자(깃헙 등)에 로그인 페이지 요청하게됨.

2. Oauth제공자는 아이디 있냐고 물어봄.

3. 사용자가 아이디 입력.

4. Oauth제공자는 코드 응답. 

5. 쿼리파라미터에 코드를 담아 서비스에 권한 요청.

6. 서비스가 코드를 담아 Oauth제공자에게 액세스 토큰 요청.

7. Oauth제공자가 액세스 토큰 답변. -> 서비스는 Oauth제공자의 api 사용 가능

##### Oauth로 api 이용

8. 유저가 브라우저를 통해 서비스에 어떤 요청을 보냄

9. 서비스가 액세스토큰을 가지고 Oauth제공자에게 그 요청을 전달함.

10. Oauth제공자가 요청에 응답함.

11. 서비스 제공자가 브라우저에게 Oauth제공자의 응답을 전달함.

    

즉 Oauth는 클라이언트가 사용자 대신 특정 리소스에 접근을 요청할 때 사용한다.



#### Oauth 1.0 vs 2.0

1. 1.0에 비해 2.0은 인증 절차가 간소화됐다. 기능 단순화 및 규모 확장성 지원을 위해 디지털 서명 기반의 암호화를 한다.https에 암호화 맡긴다.

2. 용어 변경됐다.

3. 다양한 인증 방식을 제공한다.

#### Oauth의 장점

사용자는 서비스에 id/pw를 알려주지 않아도 된다. 원할 때 액세스 토큰의 권한 취소 가능하다. 서비스는 유저의 액세스 토큰만 가지고 있으면 된다. 사용자의 id/pw몰라도 사용자가 허가해준 oauth제공자의 api 접근 가능하다.

테코브러리에서의 인가 정책도 설명해주심.



---

## 12. [Spring vs Spring Boot - 닉](https://www.youtube.com/watch?v=6h9qmKWK6Io&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=15)<a name = "Spring_vs_Spring_Boot_닉"></a>

spring의 의미는 개발자들의 겨울이 끝났다! 봄이다. 라는 것이었다. spring boot의 의미는 '조금 더 봄'으로 이해해도 좋다.

### 스프링부트의 장점

1. 스프링부트는 간단하다: 쉽게 만든다. 단독적이다. 상용화수준이다. 스프링기반이다. 스프링은 디펜던시 설정이 너무 길었다(버전까지 한땀한땀 해야함). 반면 스프링 부트는 짧다. 버전도 권장버전으로 자동 설정. starter를 쓰면 의존성 관리 고민하지 않아도 알아서 주입해준다. 스프링은 configuration 설정도 길다. spring boot는 짧다. application.properties만 써주면 된다.

2. 스프링부트는 서버 구동시간을 절반 가까이 단축시킨다. - 내장서버(톰캣)가 있기 때문이다. 톰캣을 딴걸로 바꿀 수도 있다.

3. 스프링부트는 내장 서블릿 컨테이너 덕분에 jar파일로 간단하게 배포 가능하다.



정리

1. 간편한 설정(configuration)
2. 편리한 의존성 관리 & 자동 버전 관리
3. 내장 서버를 활용해 간단한 배포 서버 구축
4. 스프링 시큐리티, 스프링데이터 등 다른 스프링 프레임워크 쉽게 쓸 수 있음.



## 13. [웹서버 vs WAS - 희봉](https://www.youtube.com/watch?v=NyhbNtOq0Bc&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=16)<a name = "웹서버_vs_WAS_희봉"></a>

### 웹서버

**웹은** 인터넷을 기반으로, 정보 공유나 검색할 수 있게 하는 서비스이다. 웹의 구성요소는 url(주소), http(통신규칙), html(내용)이다.

**서버는** 네트워크를 통해 클라이언트에게 정보나 서비스를 제공하는 컴퓨터이다.

**웹서버는** 인터넷을 기반으로 클라이언트에게 웹 서비스를 제공하는 컴퓨터이다.

### 웹서버의 아쉬움

**클라이언트 입장에서는,** 웹서버에게 주소(url)을 가지고 통신규칙(http)에 맞게 요청하면, 알맞은 내용(html)을 응답받는다. **서버 입장에서는,** 클라이언트의 요청을 기다리다가 웹 요청(http)에 대한 데이터를 만들어서 응답한다. 이 때 데이터는 웹에서 처리할 수 있는 html, css, 이미지 등 정적인 데이터로 한정한다. 근데 이런 정적인 파일만 처리하니, 아쉽다. html은 프로그래밍 언어가 아니기 때문에, 로직 처리하기가 어렵다. html을 만들기 전에, 좀 어떤 처리를 한 다음에 html을 만들고 싶다. 이러한 아쉬움 때문에 나온 게 WAS이다. 프로그래밍 언어를 활용하면 로직처리할 수 있다.

### WAS

**웹 어플리케이션은** 웹에서 실행되는 응용 프로그램이다.

**WAS는** 웹 어플리케이션과 서버 환경을 만들어 동작시키는 기능을 제공하는 소프트웨어이다. 웹 어플리케이션을 실행시켜서 필요한 기능을 수행하고 그 결과를 웹 서버에게 전달한다. 즉 php, jsp, asp와 같은 언어들을 활용하여 동적인 페이지를 생성할 수 있는 서버이다.

#### WAS의 특징

1. 프로그래밍 실행 환경과 데이터베이스 접속 기능 제공.

2. 비즈니스 로직 수행 가능.

**즉 WAS는 웹서버와 웹컨테이너가 합쳐진 것이라고 보면 된다. **컨테이너는 jsp, servlet을 실행시킬 수 있는 소프트웨어이다. 자바계열에선 WAS를 웹 어플리케이션 컨테이너라고 부르기도 함. 웹 어플리케이션 컨테이너는 웹 어플리케이션이 배포되는 공간이다.



### 웹서버, WAS의 흐름.

1. 클라이언트가 WAS(웹서버 + 웹컨테이너)에 요청.

2. 웹서버는 정적 요청인지 동적 요청인지 파악

3. 동적 요청이면 컨테이너한테 요청을 보냄.

4. 컨테이너에서 서블릿 실행됨. 동적 컨텐츠 생성.

5. 컨테이너가 웹서버에 데이터 전달.

6. 웹서버는 전달받은 데이터를 포함하여, 클라이언트가 원하는 응답을 전달.



웹서버의 예시는 아파치, 엔진엑스 등이다.

WAS의 예시는 톰캣, 웹스피어 등이다



### 웹서버와 WAS의 차이

웹서버는 정적인 컨텐츠만 다루지만, WAS는 웹서버의 개념을 연장하여, 어플리케이션을 돌릴 수 있다. 즉 상황에 따라 변하는 정보를 제공할 수 있는가가 웹서버와 WAS의 차이이다.



## 14. [빌드용어 - 에헴](https://www.youtube.com/watch?v=JgRCaVwkPE8&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=17)<a name = "빌드용어_에헴"></a>

### 컴파일 vs 빌드

컴파일은 사람이 알아보기 좋게 만들어진 파일을 컴퓨터가 알아들을 수 있는 파일로 만드는 과정이다. 컴파일했다고해서 컴퓨터가 바로 실행할 수 있는 건 아니다. 리소스(외부라이브러리, 함수(?) 등)를 사용하기 때문이다. .class파일과 외부 리소스를 연결하는 과정이 필요하다. 연결을 마치면, 실행파일(.jar)이 만들어진다. 이 과정을 링크라고 한다.

### 빌드 = 컴파일 + 링크

빌드는 누가하냐? 빌드 도구가 한다. 자바에서 빌드도구는 gradle, maven, ant 등이 있다. 빌드 도구는 소스 코드로부터 실행 가능한 어플리케이션 생성하는 것을 자동화하는 프로그램이다. 

실행 가능한 어플리케이션 생성을 빌드라고 한다.

자동화는 매번 반복적으로 수행해야 하는 일을 자동화하는것이다. 예를들어, 서비스중인 프로그램의 코드를 수정하는 경우, 여러 작업을 반복적으로 해야한다. 코드 수정 - 깃에 올리기 - 컴파일 - 링크 - 배포 등. 이 중 사람이 하지 않아도 될법한 절차가 있다. 빌드를 자동화하면 빌드자동화, 배포를 자동화하면 배포자동화, 테스트를 자동화하면 테스트자동화 라고 한다.

### 빌드 자동화가 하는 일

1. 의존성 다운로드

2. 소스코드를 이진코드로 컴파일.

3. 이진코드 패키징

4. 자동화된 테스트 실행

5. 프로덕션 시스템 배포

### 빌드 도구, 빌드 자동화를 꼭 사용해야하나?

작은 규모에서는 그럴 필요 없다. 빌드 스크립트를 짜주면 된다. 프로젝트 규모가 커지면, 뭘 해야할 지 파악하기 어렵다. 빌드 프로세스를 잘 구축해야한다.



### 자바 빌드도구 비교

ant: xml사용하여 빌드스크립트 작성. 절차적으로 빌드스크립트 작성. xml과 절차적이라는게 모순적. xml이 수직적인데, 그걸 절차적인게 이상함. 유연성이 좋음 - 빌드스크립트를 짤 때 소스코드가 어디있는지부터 어디에 저장돼야하는지 직접 작성해야하기 때문에 유연성이 좋다고함. 근데 귀찮음.

maven: pom.xml, 의존성 다운로드 가능, 컨벤션이 있음 - 사용자가 이것저것 다 하지 않아도 됨. 반대로 컨벤션과 다른 걸 하고 싶을 땐 그걸 하기 쉽지 않음.

gradle: ant와 maven의 단점 보완. 스크립트 규모가 작다 - 코드 조금만 써도 의존성 관리가 쉽다.



---



## 15. [INDEX - 안돌](https://www.youtube.com/watch?v=NkZ6r6z2pBg&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=18)<a name = "INDEX_안돌"></a>

인덱스는 검색을 위해 임의의 규칙대로 부여된, 임의의 대상을 가리키는 무언가를 말한다. 예시로 학번, 주민등록번호 등이 있다. 무언가를 찾을 수 있는 키라고 생각하면 된다.

### INDEX 관련해서 고민해볼 것들

1. 데이터베이스는 내가 원하는 데이터를 어떻게 찾아오는 걸까?

2. 데이터가 많아질수록 왜 느려질까?

3. 조인을 수행하면 왜 느려질까?

4. 왜 쿼리가 느릴까?



### Clustered vs Non-Clustered

#### Clustered Index

cluster는 군집을 의미하고, cluestered는 군집화를 말한다.clustered index는 군집화된 인덱스(데이터 + 인덱스)를 말한다. 쉽게 생각하면(?) 인덱스와 데이터가 군집이다. 이런 군집에서 데이터를 넣고 싶다면? 예를 들어, 등수별로 저장된 데이터가 있을 때 중간에 데이터를 넣고 싶으면 걔를 위한 자리를 만들어주고 그 자리에 데이터 넣어주고 번호 매겨줘야한다. 이게 클러스터드 인덱스의 특징이다. pk와 유사하다. 정렬 기준이 하나만 존재할 수 있다(한 테이블에 하나만 있음). 범위검색 짱(공간지역성이 유사한 애들을 쫙 가져오면 됨 - 빠름). 존재하는 Pk사이에 인서트할 경우 대참사(왜 auto increment를 하는지 알 수 있을것).

##### Clustered Index의 특징

1. 순서대로 정리돼있음. 
2. 이미 등수별로 정리돼있기 때문에, 검색할 때 강력함. 
3. 중간에 클러스터드 인덱스가 삽입돼야한다던지 하면, 정렬하는 비용이 커질 수 있음(밀어내야하니까..).



#### Non-clustered index

데이터랑 연결돼있는 게 아니라, 인덱스랑 연결됨 - 간접참조함.

예를 들어, 45등은 123번에 가면 있다. 20등은 214에 가면 된다. 와 같이 저장돼있음 - 순서랑 상관없고, 데이터를 직접 가지지 않는다.. 중간에 참조를 거치기때문에 굳이 순서대로 하지 않아도 됨. 해시 방식으로 돼있어 빨리 찾을 수 있음. Non-clustered Index는 순서가 상관 없음. 한 테이블에 여러개일 수 있음. 추가 저장 공간 필요(약 10%)(인덱스가 어느 위치에 있는 지 알아야하고, 클러스터드 인덱스를 참조하기 위해서). 인서트 시 추가작업 필요(인덱스 생성해야함.) Cardinality: 인덱스의 효과를 평가할 수 있는 항목. 어떤 인덱스는 쓸모없을 때가 있음. 중복되는 것들이 많을 수록 카디널리티(성능)은 낮아지고, 유일한 값일수록 카디널리티는 높아짐. 뭘 인덱스로 삼을 지 결정할 때 기준이 됨.



### Example

이메일을 pk로 하면 db성능 이슈가 있을 수도 있음. 특정 이메일이 들어올 때, 자리 다비켜줘야해... 이메일은 유니크로 주고, 다른애를 피케이하는게 나음. 그런데 만든 사람은 Pk를 알지만 사용자는 모르기 때문에, 결국 pk가 아닌걸로 검색해야 함. 이메일을 기준으로 찾는 게 0.6초라고하면, 이메일로 찾은 다음에 그 찾은걸로 다시 찾으려면 0.6초는 기본으로 깔리는거임. 인덱싱 처리만 잘 해도 성능을 팍 올릴 수 있음. 인덱스가 무조건 많다고, 적다고 좋은 게 아님. 많을 경우, 검색이 빨라질 수도 있지만 생성할 때 그만큼 느려지는거. 참고로, 커뮤니티가 활성화되려면 십만명정도가 필요하다고 함.



### Advanced Keyword

1. explain(실행계획): mysql이 이 쿼리 어떻게 실행할 지 계획을 미리 알려주면, 그걸 분석해서 튜닝할 수 있음.

2. B-tree(balanced tree), page(block) in innoDB

3. cardinality

4. composite key

5. innodb_buffer_pool_size

7. log_throttle_queries_not_using_index: 오래걸리는 쿼리 로그 남김.



---

## 16. [TCP UDP - 르윈](https://www.youtube.com/watch?v=ikDVGYp5dhg&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=19)<a name = "TCP_UDP_르윈"></a>

transport layer는 endpoint 간 **신뢰성**있는 데이터 **전송**을 담당하는 계층이다. 신뢰성은 데이터를 순차적, 안정적으로 전달하는 걸 말한다. 전송은 포트 번호에 해당하는 프로세스에 데이터를 전달하는 걸 말한다.

### 전송계층이 없다면?

1. 데이터 전송이 순차적으로 되지 않을 수 있음.

2. 흐름문제가 생길 수 있음. 송수신자 간의 데이터 처리 속도가 차이나기 때문. 송신자는 원하는만큼 막 보내는데, 수신자의 처리속도가 더딜 수 있음. 처리할 수 있는 데이터를 초과하면, 데이터가 누락됨.

3. 혼잡문제가 생길 수 있음. 네트워크의 데이터 처리 속도(ex: 라우터)가 느릴 수 있기 때문. 네트워크가 혼잡하면 송신자가 보내도 수신자한테 안감. 결국, 데이터 손실이 발생할 수 있음.

이러한 문제를 해결하기 위해 TCP를 고안함.



### TCP

신뢰성있는 데이터 통신을 가능하게 해주는 프로토콜을 말한다.

#### TCP의 특징

1. 커넥션을 연결함(3 -way-handshake) : 양방향 통신을 함.

2. 데이터의 순차 전송을 보장.

3. 흐름 제어

4. 혼잡 제어

5. 오류 감지

**세그먼트는** 데이터를 전송할 때 쓰는 단위이다. 어플리케이션 레이어에서 데이터를 전송하려고 하면, TCP가 데이터를 자른다. 자른 데이터에 TCP 헤더 추가한 걸 세그먼트라고 한다. **TCP 헤더는** 포트정보(전송을 하기 위해 꼭 필요함), 시퀀스넘버, acknowledgement 넘버(전송계층에서 순차전송의 신뢰성을 보장할 수 있게 해줌), 9 비트 flag field(tcp 연결을 제어하고, 데이터 관리) 등으로 구성된다. 9 비트 flag 중 중요한 세가지는 ACK, SYN, FIN이다. **SYN은** TCP가 커넥션을 연결하는데, 그 때 쓰인다. **FIN은** 커넥션을 연결했다가 나중에 끊어야하는데 그 때 쓰인다. **ACK는** 데이터 전송하면, 받는사람이 있을텐데 그 받은 사람이 데이터 제어할 때 쓴다.

#### 3-way-handshake(커넥션 연결) 과정 

1.  클라이언트가 서버에 연결을 요청할 때, SYN 비트를 1로 설정하고 패킷을 송신한다.
2. 서버가 그 패킷을 받으면, ACK비트를 1로 설정하고 패킷 송신하여 데이터를 받았다는 걸 알린다. 또한, 나도 너와 연결하고 싶다는 의미로 SYN도 1로 설정한다.
3. 클라이언트가 서버의 패킷을 받으면, 얘도 나랑 커넥션 맺고 싶구나라고 생각하여, 통로를 연결하고, ACK를 1로 설정하여 알았다는(잘 연결됐다는?) 신호를 보낸다. 커넥션이 연결되면 상태가 established로 바뀐다.

#### 커넥션 연결 후 데이터 송수신 흐름.

1. 클라이언트가 패킷을 보낸다.
2. 받은 곳에서는 무조건 ACK를 보낸다. 잘 받았다는 의미이다. 
3. 만약 서버가 클라이언트의 패킷을 받지 못한다면, 서버는 가만히 있을거고, 클라이언트는 서버의 ACK를 기다리다가 안오네 하면서 다시 패킷을 보낸다.

#### 4-way handshake(커넥션 중단) 과정

1. 데이터를 전부 송신한 클라이언트가 FIN을 1로 설정 후 패킷 보낸다.
2. 서버는 데이터를 잘 받았다고 ACK를 1로 설정 후 패킷 보낸다. 중요한 게 클라이언트는 자기가 보낼 거 다 보냈지만, 서버는 아직 보내고 싶은 게 남아있을 수 있다. 클라이언트는 서버가 데이터를 더 보낼 수 있도록 잠시동안 기다린다. 서버가 데이터를 다 보낸다.
3. 서버가 FIN 1로 설정 후 패킷 보낸다. : 클라이언트의 커넥션 상태가 closed로 바뀐다.
4. 클라이언트가 알았다고 ACK를 1로 설정 후 패킷 보낸다. - 서버의 커넥션 상태 closed로 바뀐다.

#### TCP의 문제점

전송의 신뢰성은 보장하지만, 매번 커넥션을 연결(3-way handshake)하기 때문에 시간 손실이 발생한다. 패킷을 조금만 손실해도 재전송을 꼭 해야한다. 이 특징은 중요한 데이터한테는 장점이 되지만, 별로 안중요한? 데이터도 재전송을 해야한다. 상황에 따라 단점이 될 수 있다.



### UDP

TCP보다 신뢰성이 떨어지지만, 전송속도가 일반적으로 빠른 프로토콜(순차 전송 X, 흐름 제어 X, 혼잡 제어 X)이다. connectionless하다는 특징을 갖는다. 영상스트리밍과 같이 비교적 데이터 신뢰성이 중요하지 않고, 속도가 중요할 때 사용한다. TCP에서는 segment를 나눠줬지만, UDP는 user datagram을 데이터 단위로 사용한다. 어플리케이션 레이어에서 내려온 데이터에 UDP Header를 추가해주고, segment와 달리 데이터를 쪼개지 않는다. 따라서 어플리케이션레이어에서 직접 데이터를 쪼개줘야 한다. UDP 헤더는 전송을 위해 필요한 포트번호, 오류감지를 위한 16비트의 checksum 로 구성된다.

#### UDP의 데이터 전송과정

커넥션 없으니, 확인이 없다는 뜻. 그냥 무조건 보낸다. 서버는 UDP 통신을 위한 소켓을 열어두고 있는다. 

즉, 과정이 '클라이언트가 패킷 송신' 이 끝이다.



### 중요한 점

1. TCP, UDP의 특성을 파악하고 상황에 따라 적절한 프로토콜을 사용해야 한다.

2. TCP, UDP의 헤더에 대해 파악하고 성능 개선에 이용할 수 있어야 한다.



## 17. [API vs Library vs Framework - 티버](https://www.youtube.com/watch?v=We8JKbNQeLo&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=20)<a name = "API_vs_Library_vs_Framework_티버"></a>

### API

**API는** 응용 프로그램에서 운영체제나 프로그래밍 언어가 제공하는 기능을 제공할 수 있게 만든 인터페이스이다. API는 프로그램 사이를 연결해주는 다리 역할을 해준다. 예를 들어, 구글이 '구글맵 쓰고 싶으면 이러이러하게 요청을 보내' 라고 가이드를 준다. 나는 구글의 가이드대로 요청을 보내고, 원하는 정보를 받는다. 이 때 다리역할을 하는 게 API이다.

#### API의 특징

1. 구현 내용 없이 사양만 정의돼있다.

2. API에 따라 접근 권한이 필요할 수 있다.

3. 기업이 제공하는 api가 많으니 프로젝트 수행 시 잘 활용하는 것도 개발자의 능력이라고 할 수 있다.



### Library

필요한 책을 빌리기 위해 책이 모여있는 도서관에 가는것처럼, 라이브러리는 응용프로그램 개발을 위해 필요한 기능(함수)을 모아놓은 소프트웨어를 말한다.

#### Library의 특징

1. 독립성을 가진다 - 다른 것(라이브러리)에 의존하지 않는다.

2. 응용프로그램이 능동적으로 라이브러리를 사용해야 한다.

3. 기능이 필요할 때 응용프로그램(내가 만든거)이 라이브러리를 호출한다.



### Framework

Framework는 응용프로그램이나 소프트웨어의 솔루션 개발을 수월하게 하기 위해 제공된 소프트웨어 환경(틀이 있고, 개발자가 그 안에서 코드 작성)이다.

#### Framework의 특징

1. Framework는 상호 협력하는 클래스와 인터페이스의 집합이다.

2. 응용프로그램이 수동적으로 프레임워크에 의해 사용된다. 즉, 프레임워크가 응용프로그램을 호출하는 것이다.



### 차이점

1. Library와 API의 차이점은 구현 로직의 유무이다.

2. Library와 Framework의 차이점은 응용프로그램의 흐름 주도권을 누가 가지고있냐이다.



## 18. [Hash Function - 코니](https://www.youtube.com/watch?v=Rpbj6jMYKag&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=21)<a name = "Hash_Function_코니"></a>

프로그래밍하면서 자료를 저장할 때 적절한 자료구조를 선택해야한다. 예를 들어, 배열을 사용할 경우, 원소 하나를 저장하고 검색하는 데 n의 시간이 필요하기 때문에, 이걸 트리로 개선하면 더 좋다. 트리는 log(n)의 시간 소요된다(균형잡힌 트리는 최악에도 log(n)). 배열이든 트리든 자료의 양에 따라 검색 시간이 영향을 받는다. 저장된 자료의 양에 상관없이 원소 하나를 저장하고 검색하는 것을 상수시간에 가능하게 할 수는 없을까? 해시테이블을 사용하면 가능하다.

### 해시테이블

데이터를 해시함수에 넣고 해시함수의 결과값에 데이터를 저장(키: 해시함수의 결과값, 밸류: 데이터). 즉, 임의의 원소를 해시테이블에 저장하려면

1. 해시함수를 이용해 해당 원소의 해시값을 계산
2. 해시값을 주소로 하는 위치에 원소 저장.
3. 저장 후 검색할때도 원소의 해시값을 계산해 바로 해당 위치로 이동.

해시테이블은 원소를 저장할 위치를 상수시간에 계산할 수 있다. 해시테이블이 배열,트리와 다른점은 배열,트리에서 검색하려면 기존에 저장된 자료와 원소를 하나하나 비교해야하지만, 해시테이블은 저장된 자료와 비교할 필요 없이 바로 저장 및 검색할 수 있다. 해시함수는 임의의 길이의 데이터를 고정된 길이의 데이터로 매핑하는 함수이다.

#### 좋은 해시함수의 조건

1. 계산이 간단해야 한다.

2. 입력 원소가 해시테이블 전체에 골고루 저장돼야 한다. 해시충돌이 발생할 수 있기 때문이다.

##### 해시충돌의 해결 1: 체이닝

같은주소에 해당하는 원소를 연결리스트로 만든다. 해시충돌을 해결할 수 있지만, 해시함수의 장점을 제대로 살리지 못하게된다.

##### 해시충돌의 해결 2: 개방 주소 방법

체이닝과 달리 주어진 테이블 공간 안에서 해결한다. 그러려면 모든 원소가 반드시 자신의 해시값과 일치하는 주소에 저장될거라는 보장이 없게된다. 개방 주소방법의 예시로는 선형조사, 이차원조사, 더블해싱가 있다.

1. 선형조사: 가장 간단한 충돌해결 방법이다. 충돌이 일어난 자리에서 다음 위치로 이동한다. 테이블 범위를 넘어가면 맨 앞으로 돌아간다. 저장하거나 검색하는 데 시간이 좀 더 걸릴 수도 있고, 빈 공간이 채워지면서 데이터가 몰릴 수 있고, 연산횟수가 늘어날 수 있다.

2. 이차원조사: 선형조사처럼 바로 뒷자리를 보는 게 아니라 보폭을 넓혀 다음 위치로 이동한다. 원소들이 특정 위치에 몰릴 수 있지만 그래도 좀 분산시킬 수 있다.

3. 더블해싱: 두 개의 해시함수를 이용한다. 첫 함수는 최초 해시값을 얻을 때 사용하고, 두번째 함수는 해시충돌을 해결하기 위해 사용한다. 두 해시값이 같을 가능성이 적다는 걸 이용하여 충돌 피한다.



#### 해시함수의 특징

1. 같은 입력에 대해 같은 출력이 보장된다.

2. 서로 다른 입력값으로부터 동일한 출력값이 나올 가능성이 희박하므로, 입력값에 무결성이 보장된다.

3.. 일방향성을 가진다.

#### 해시알고리즘 예시: SHA

SHA256에서 256의 의미는 해싱을 하면 2의 256승개의 해시값 중 하나가 나온다는 거다. 해시함수는 입력값이 조금만 달라져도 출력이 완전히 달라진다.

#### 해시의 활용

1. 무결성 검사: 데이터 다운받을 때나 변조 위험이 있을 때 해시값 비교해서 파일이 변했는지 알 수 있다.
2. 클라우드 스토리지에서 동일한 파일 식별 및 수정된 파일 검출한다.
3. 데이터베이스에 비밀번호를 저장할 때 사용한다.
4. 블록체인에 활용한다.
5. git에 활용한다.



---

## 19. [요청 응답 흐름 과정 - 철시](https://www.youtube.com/watch?v=4SaW9BbtL3k&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=22)<a name = "요청_응답_흐름_과정_철시"></a>

어플리케이션 레이어의 http에 집중한 내용이다. 브라우저는 웹서버에 원하는 정보를 요청하고 응답받아 사용자에게 보여준다. 브라우저가 요청을 할 때, url(네트워크 상 자원이 어디에 있는 지 알려주는 규약)을 활용한다. 브라우저에 url을 입력했을 때 브라우저가 처음 하는 일은 url을 해석해 요청을 만드는 것이다. url 구조는 프로토콜(http) - scheme, 도메인, 포트번호, 파일의위치/요청path, 쿼리스트링로 구성된다. 즉, url은 웹서버에 무엇을 요청할 것인가를 정의한다. 브라우저는 요청을 할 때 http method활용를 활용한다. http method는 url로 특정 자원을 어떻게 처리할 것인지 정의한다.

### 요청 만들기

http 메서드, 요청 path, http version을 합쳐 request line을 만든다. 요청에 필요한 추가정보(header name, header value)로 message header를 만든다. 필요 시 message body를 만든다.

요청을 다 만들어서 서버에 보내면, 서버는 요청을 해석해서 응답을 만든다.

### 응답 만들기

http version, status code, 응답문구를 합쳐 status line을 만든다. 응답에 필요한 추가정보(header name, header value) - message header를 만든다. 필요 시 message body 만든다.

### 응답을 유저에게 보여주기

브라우저는 응답을 받은 후 그걸 유저에게 보여줘야한다. 내용의 형식인 content-type은 다양하고, 타입에 맞게 보여줘야 한다. 다른 건 다 똑같은데, content-type만 다르게 할 경우 브라우저가 해석을 못한다.

### 헷갈렷던 것

#### domain vs host

domain은 한 네트워크를 대표하는 이름이다.하나의 서비스(네이버)를 대표한다고 생각할 수 있다. host는 네트워크에서 고유하게 식별하는 기기(컴퓨터, 파일서버, 복사기 등)의 이름이다. 예를 들어, cafe.naver.com이 있으면 cafe가 호스트고 naver.com이 도메인이다. host + domain = FQDN인데, 일반적으로 FQDN을 그냥 domain이라고 부르는 것 같다.

#### uri vs url

uri는 한 자원의 식별자이다. uri은 url과 urn으로 나뉜다. url은 한 리소스에 대한 구체적인 위치 서술한다. urn은 리소스의 위치와 관계없는 이름이다.



---

## 20. [Process & Thread - 김고래](https://www.youtube.com/watch?v=LLiV5Yz1AWg&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=23)<a name = "Process_&_Thread_김고래"></a>

### 프로세스

**프로그램은** 코드의 집합이다. 즉 명령어, 코드 및 정적 데이터의 묶음이라고 보면 된다. **프로세스는** 실행중인 프로그램을 말한다. 구체적으로는 운영체제로부터 시스템 자원을 할당받는 작업의 단위이다. 작업관리자 가면 프로세스, 쓰레드 상황을 볼 수 있다.

#### 프로세스의 구성

1. 텍스트: 내가 짠 코드를 말한다.

2. data: 전역변수. 스태틱으로 선언한거를 말한다.

3. heap: new 객체 해서 만든 거. 동적으로 할당되는 메모리이다.

4. stack: 매개변수, 지역변수 등 임시적인 자료이다.

운영체제에서 여러 프로세스가 동작하는데, 이게 동시에 작동하는 게 아니라 빠르게 바뀌면서 조금씩 실행시키는 것이다(?). 운영체제가 프로세스를 관리해야하는데, 각 프로세스를 PCB(process control block)라고 표현한다. PCB는 pid, 프로세스 상태(new, ready, running, wating, halted 등), 프로그램 카운터(다음 실행할 명령어의 주소), 스케쥴링 정보(우선순위 등) 등을 관리한다.

#### 멀티프로세스

멀티쓰레드와 달리 자원 공유 불가하다. 자원을 공유하려면 프로세스 간 통신(IPC - Interprocess communication)이 필요하다(소켓, 파이프 등). 따라서 자원을 공유하는 데(context swiching) 비용이 많이 든다. 자식 프로세스 중 하나가 문제 생겨도 다른 프로세스에는 영향이 없다. 예시로, 크롬에서 탭들은 각각 다른 프로세스이다. 한 탭에 문제 생겨도 다른 탭은 멀쩡하다. 브라우저프로세스는 유알엘 자동완성기능 등 해주고, 렌더러프로세스는 응답받은 정보를 화면에 띄어주는 역할을 해주고, 플러그인프로세스는 플러그인들을 관리하고, gpu프로세스는 렌더러의 작업을 보조하는데, 이러한 프로세스들은 각기 독립적이다.



### 쓰레드

쓰레드는 프로세스 내에서 실행되는 흐름의 단위이다. cpu 이용의 기본 단위라고 생각해도 된다. 한 프로세스는 한 개 이상의 쓰레드를 가질 수 있다. 쓰레드들은 프로세스의 text, data, heap를 공유한다. 각 쓰레드는 별도로 stack을 가진다. 프로세스가 두 개 이상의 쓰레드를 가질 때 멀티쓰레드라고 한다.

#### 멀티쓰레드

프로세스의 자원 공유을 공유한다. 향상된 응답성(?)을 가진다. context switching 비용이 적다. 자원을 공유하는만큼 충돌에 주의해야한다(thread-safe하게). 멀티쓰레드의 예로, 웹서버는 하나의 페이지를 요청받으면 여러 쓰레드 생성한다.



정리하자면, 하나의 운영체제 안에 여러개의 프로세스가 있고, 각 프로세스에 여러 개의 쓰레드가 있고, 각 쓰레드에 여러개의 파일 보관(? 잘못들음)한다.



## 21. [Interrupt와 Context Switching - 코맥](https://www.youtube.com/watch?v=-4HKhwlH3FQ&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=24)<a name = "Interrupt와_Context_Switching_코맥"></a>

IntelliJ의 파일 자동 저장 과정(단일cpu, 프로세스 단위별 기준)을 예시로 설명한다. 파일 자동 저장은 저장공간 확인 -> 저장 경로 확인 -> 저장 파일 확인 -> 저장의 과정을 거친다. 이 과정을 진행하는 중 사용자가 키보드 입력하면 interrupt 발생한다. 그걸 cpu한테 알려준다. Interrupt가 발생하면 프로세스가 하던 일을 멈추고 이미 정해진 코드에서 요청에 대한 처리를 수행한다. 이 Interrupt는 예측 가능해서, 운영체제가 제어 가능하다. 사용자 입력 뿐 아니라, 프로그램에서도 시스템 콜을 하면 인터럽트가 발생.



### 인터럽트 과정 

메모리는 os부분이랑 유저프로세스로 나뉨. 

1. 저장경로 확인 로직 실행
2. 키보드 인터럽트 발생
3. 현재 실행중인 프로세스 정보(문맥)를 저장 - 인터럽트 처리 후 현재 프로세스로 다시 돌아오기 위해.
4. 인터럽트 벡터에서 해당 인터럽트를 처리하는 서비스 루틴(ISR)을 찾음
5. cpu가 해당 서비스 루틴을 처리하는 주소를 설정(?)
6. 인터럽트 처리
7. 저장 경로 확인 로직(원래) 주소로 돌아감(?)

3,4,5 => 현재 실행중인 프로세스 정보를 저장하고 다른 프로세스로 넘어가는데, 이러한 과정을 context switching이라고 한다.



### Context switching 

하나의 프로세스가 CPU를 사용중인 상태에서 다른 프로세스가 CPU를 사용하도록 하기 위해, 이전 프로세스의 상태(Context)를 보관하고, 새로운 프로세스의 상태를 적재하는 작업(인터럽트를 처리하는 프로세스)을 말한다. 한 프로세스의 Context는 그 프로세스의 프로세스제어블록(PCB)(프로세스의 모든 정보를 저장해놓음)에 기록돼있다.

#### PCB에 저장돼있는 것

1. 프로세스 상태
2. 프로세스 식별자
3. 다음 실행할 명령어 주소(pc) - program counter: cpu가 수행하는 명령어 주소.
4. registers
5. memory limits(메모리 관리 정보)
6. list of open files(입출력 상태 정보)

#### Context Switching 과정

P0에서 P1으로 옮긴다고 치면, P0에 컨텍스트 저장하고, P1을 실행시키기 위해 CPU가 P1정보를 가지고 온다. P1 실행한다. P1에서 다시 P0로 가려면 P0에서 P1로 온것처럼 하면 된다. 아무것도 안하는 상태(idle)가 겹치는 걸 overhead라고 한다(cpu가 메모리를 적재하느라고 아무것도 안함). 이건 cpu를 낭비하는 것이다.



---

## 22. [Servlet & Spring - 규동](https://www.youtube.com/watch?v=cmwmamOQmPc&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=25)<a name = "Servlet_&_Spring_규동"></a>

**서블릿은** HTML 등의 웹 컨텐츠를 생성하고 전달하기 위해 Servlet 인터페이스의 구현규칙을 지켜 자바로 만들어진 프로그램이다. 각각의 서블릿은 서블릿 인터페이스를 상속받아 구현하고 있다. 서블릿 컨테이너가 서블릿들을 가지고 있다. **스프링은** 자바 엔터프라이즈 개발을 편리하게 해주는 오픈소스 애플리케이션 프레임워크다.

### 서블릿이 나오게 된 배경

예전에는 정적 웹페이지밖에 없었다. 근데 동적웹페이지가 나오게 된다(웹어플리케이션서버를 통해 로직 수행). 동적웹페이지의 경우 어플리케이션과 서버가 통신해야하는데, 환경도 다르고 언어도 다르고 하니까 통신 규약이 필요하다. 그래서 나온 게 CGI이다. **CGI는** http 통신규약을 사용하는 웹서버가 프로그램(웹 어플리케이션)과 데이터를 주고 받는 규약이다. 서블릿 이전에는 직접 구현했다. **CGI의 단점은** 하나의 클라이언트가 요청을 하면, 하나의 프로세스가 실행되고, 그 요청을 처리하면 프로세스가 종료되기 때문에 비효율이라는 것이다.또한 주로 사용된 언어인 펄이 텍스트 처리 위주이기 때문에 객체 지향이 적용안됐다. 자바 서블릿이 나오면서 객체지향, 멀티스레드, 보안 등 적용했다. 서블릿도 CGI 규칙에 따라 데이터를 주고받지만, 직접적으로 통신하는 것은 서블릿 컨테이너에게 위임하고, 대신 서블릿 컨테이너와 서블릿 간에 규칙(서블릿 규약)이 존재한다. 

### 서블릿의 흐름

하나의 요청에서 하나의 프로세스가 꺼졌다 켜졌다 하는 구조가 아니다. 서블릿 컨테이너 내부에서 서블릿이 쓰레드 단위로 요청을 처리한다. 서블릿은 나름의 라이프사이클을 가진다. 서블릿의 흐름은 개발자가 직접 하는 게 아니라, 서블릿 컨테이너가 한다.

### 서블릿 구현

서블릿은 웹서버 내부에서 동작하는 작은 자바 프로그램이다. 서블릿은 일반적으로 HTTP를 통해 웹 클라이언트로부터 요청을 수신하고 응답한다. 서블릿 인터페이스를 구현하기 위해선 GenericServlet을 상속받거나 HttpServlet을 상속받아 구현한다.

#### 서블릿의 라이프사이클

1. 서블릿 생성 - init() 호출. 
2. 클라이언트의 요청은 service()가 처리.
3. 서블릿이 서비스를 마치게되면, destory()를 호출하여 종료됨. 이후 GC가 메모리 정리해줌.

리퀘스트가 끝났다고해서 꼭 메모리에서 제거하는 게 아니고, 생성된 서블릿 객체는 메모리에 남겨뒀다가 동일한 요청이 들어오면 init() 호출 없이 재사용한다.

#### 서블릿의 상속구조

톰캣 내부에는 Servlet(인터페이스) / GenericServlet / HttpServlet가 들어있다. 스프링 쪽에서 톰캣에 있는 것들을 상속하고, HttpServletBean / FrameworkServlet / DispatcherServlet이 들어있다. 각각의 역할을 살펴보면,

1. Servlet: 필요한 함수 정의

2. GenericServlet: 다른 건 구현하는데, service()는 abstract로 구현안함.

3. HttpServlet: service() 구현 - method를 찾아서, method별로 함수(doGet등) 호출. 그런데 그 함수를 보면, 어떤 처리 없이 에러 호출만 함.

4. HttpServletBean: 함수(doGet등)을 오버라이드 하지 않음. 그냥 HttpServlet을 빈으로 등록해주기만 함.

5. FrameworkServlet: 여기서 doGet을 오버라이드해서, 처리(processRequest 실행)함. doService() 구현안함.

6. DispatcherServlet: doService() 구현. doDispatch등 호출. 핸들러 매핑, 핸들러 작동시켜 ModelAndView 얻음, processDispatchResult 호출하여 렌더링.



---

## 23. [MVC - 제이엠](https://www.youtube.com/watch?v=nMolWzTT-dU&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=26)<a name = "MVC_제이엠"></a>

모델은 평범한 자바 객체이다. 모델의 역할은 도메인 객체 혹은 DTO, Database와 연관있다. View는 Html, jsp, 타임리프 등과 관련이 있고 역할은 데이터를 보여주는 것이다. Controller는 UserController같은 것이고, 역할은 사용자 입력을 받아 모델 객체의 데이터를 변경하거나 뷰에 전달하는 것이다.

### MVC 장점

1. 동시다발적 개발 - 백엔드/프론트

2. 높은 응집도: 논리적으로 관련있는 것들을 묶음.

3. 낮은 의존도: 뷰,모델,컨트롤러 각각 독립적.

### MVC 단점

배우기 어렵다.



MVC패턴과 미션을 연결지어 설명해주심.

기존의 서블릿 역할을 MVC가 나눠갖는 거라고 생각하면 된다.



---

## 24. [Connection Pool & Keep-Alive - 쿠기](https://www.youtube.com/watch?v=MBgEhSUOlXo&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=27)<a name = "Connection_Pool_&_Keep-Alive_쿠기"></a>

### DB에 접근하는 서비스 요청 처리 과정

1. 매 요청마다 커넥션 필요해서, 매 요청마다 커넥션 생성함.
2. 커넥션으로 요청 처리
3. 커넥션을 닫음.

커넥션 생성이 오래걸리기 때문에, 풀을 두고 가져가서 씀.

### 커넥션 풀 만들 시 고려사항

1. 커넥션 풀이 너무 작으면 대기하는 요청이 많아짐.
2. 커넥션 풀이 너무 크면 메모리 낭비
3. 접속자 수, 서버 부하 고려

### Http를 활용할 때 고려사항

1. TCP handshake 설정
2. 인터넷 혼잡을 제어하기 위한 slow start(갑작스러운 부하와 혼잡을 막기 위함)
3. time_wait 지연과 포트 고갈

tcp가 전송할 수 있는 패킷 수는 tcp 커넥션이 만들어진 지 얼마나 지났는가에 영향을 받는다. 데이터가 성공적으로 전송됨에 따라 전송하는 패킷 수 늘려간다.

time_wait는 클라이언트, 서버 중 커넥션 close한 쪽에 지연이 발생되는 걸 말한다. ip주소와 포트번호를 메모리에 저장하고, 이 ip주소/포트번호를 사용하는 connection을 일정시간동안 생성하지 않기 위함이다. 잘못된 패킷을 받아 오동작할까봐. time_wait로 인해, 요청이 많아지면 포트가 고갈될 수 있다.

병렬 커넥션과 지속 커넥션을 통한 connection pool 방식으로 tcp통신의 문제점(slow start, 포트고갈 등)을 해결할 수 있음.

### 병렬커넥션

장점

1. http 클라이언트가 여러개의 커넥션을 맺음으로써 여러 트랜잭션을 병렬로 처리

2. 페이지를 더 빠르게 내려받는 효과.

3. 최신 브라우저는 6~8개의 병렬 커넥션 활용.

단점

1. 커넥션이 많으면 메모리를 많이 소모하여 성능문제 발생할 수 있음.

2. 커넥션마다 slow start가 있어서, 성능이 안좋아질 수 있음.

3. 각 트랜잭션마다 handshake가 있어서 성능이 안좋아질 수 있음.



### 지속 커넥션

장점

1. handshake 최소화

2. slow start 최소화

3. 연결 최소화 -> time wait 줄어듬.

단점: 잘못 관리할 경우 연결되어있는 커넥션이 쌓여 불필요한 리소스가 발생할 수 있음.



**따라서 적은 수의 병렬커넥션만 유지하고 그걸 지속하는 게 효과적이다. 이게 Http Connection Pool인가 하고 생각하심.**



### 지속 커넥션 타임

1. Keep Alive 커넥션(http 1.0): 커넥션을 유지하기 위한 헤더 활용.
2. 지속 커넥션(http 1.1)

### Keep Alive 커넥션 사용할 때 제한과 규칙

1. 정확한 content-length값을 주고 멀티파트 미디어형식이거나, 청크 전송 인코딩 돼야 함.
2. 프록시와 게이트웨이는 메시지를 전달하거나 캐시에 넣기 전에 Connection Header를 제거해야함.
3. keep alive가 http1.1에선 빠졌지만 아직도 브라우저 - 서버 간 사용되기에 keep alive 처리할 수 있게 어플리케이션 만들어야 함.

### Dump Proxy

프록시를 통해 keep-alive 정보를 주고받으면, 클라이언트와 서버는 서로 connection 유지중이라고 알고있는데 프록시는 커넥션 헤더를 모르기에 유지중인데도 커넥션 끊어지길 기다리는 상황이 생길 수 있다. 이를 해결하기 위해 Proxy Connection 헤더 사용한다. 프록시 서버가 keep alive 알아들을 수 있게 한다.

### http 1.1의 지속커넥션

1. keep-alive와 달리 디폴트로 활성화됨.
2. 오히려 끊고 싶으면 Connection: close 헤더를 명시해야함.
3. 헤더가 없어도 그냥 클라이언트가 서버가 통신을 끊을 수 있음.



## 25. [Forward Proxy vs Reverse Proxy - 쉐이크반](https://www.youtube.com/watch?v=lg-wHikZg0Q&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=28)<a name = "Forward_Proxy_vs_Reverse_Proxy_쉐이크반"></a>

프록시는 클라이언트와 서버 사이의 중계역할을 한다. 클라이언트의 요청을 받아 서버에 대신 요청한다. 서버의 응답을 받아 클라이언트에 전달해준다. 프록시 역할을 하는 서버를 프록시서버라고 한다.

### 프록시 서버 역할

1. 클라이언트의 요청을 서버에 전달하고, 서버의 응답을 클라이언트에 전달.
2. 캐시를 통해 자원 관리 가능. -> 네트워크 비용 감소, 응답속도 향상.
3. 필터 기능(프록시서버를 거치는 요청, 응답을 확인 가능). - 예를 들어, 어린이의 음란사이트 접속을 막음. 접속권한이 있는 지 확인 -> 보안 향상. 로깅을 통해 요청 응답도 확인 가능.
4. 데이터를 어느정도 조작 가능(데이터압축, 언어변환, 익명화 등). 예: 스페인어 사용자를 위해 언어변환, 웹브라우저 설치된 모바일 사용자 - 데이터가 너무 보기 어려우니 좀 글씨를 작게해준다거나.. => 데이터를 압축하면 네트워크 비용 감소, 원래 서버의 역할 감소. 익명화 - 클라이언트의 요청에 클라이언트의 정보가 다 들어있음... 걸러서 서버에 전달 => 보안성 향상.

Forword Proxy는 클라이언트 대신 서버에 요청을 보내준다(클라이언트와 소통).

Reverse Proxy는 서버의 응답을 대신 클라이언트에 전달해준다(서버와 소통).

클라이언트, 서버가 서로를 모르게 할 수 있기 때문에 보안성이 향상된다

> 궁금한 점: 그런데 프록시를 털어버리면 보안이 좋아졌다고 할 수 없는거 아닐까?

로드밸런싱은 여러 대의 서버에 요청을 나눠 보내준다. 리버스 프록시가 로드밸런싱도 수행한다. nginx를 프록시 서버로 두고, 무중단 배포를 구현했다. nginx가 리로드 하는 시간은 체감하기 어렵기 때문에 중단이 없었다..?



## 26. [TLS - 에단](https://www.youtube.com/watch?v=EPcQqkqqouk&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=29)<a name = "TLS_에단"></a>

네트워크, 보안과 관련된 키워드이다. cli로 내가 원하는 호스트까지 도달하기까지 거쳐야하는 경로를 확인할 수 있다. 거쳐야 하는 경로가 많다는 게 문제다. 구체적으로 다음이 문제다.

1. 경로에 있는 애들은 내가 보낸 데이터를 볼 수 있음.
2. 내가 통신하는 상대방이 내가 원했던 애인지 알 수 없음(중간에서 척하면 알 수가 없음).
3. 요청이 변조되지 않았다는 걸 보장하지 못함.

http로는 이 문제를 해결할 수가 없다.

### TLS(transport layer security, 전송계층보안)

보내는 쪽은 응용계층에서 데이터를 암호화해서 전송계층에 보내주고, 받는 쪽에서는 전송계층에서 복호화해서 응용계층에 보내준다. tcp 443포트 사용한다. tls 전에 ssl이 있었다. ssl도 앞선 문제를 해결할 수 있지만, 이걸 좀 개선해서 tls가 됐다.

#### TLS의 기능 

1. 암호화: 정해진 대상만 메시지 확인 가능.
2. 인증: 메시지 발신자의 신원 확인. 지금 내가 통신하고 있는 애가 진짜 내가 원하던 애였는 지 확인.
3. 무결성: 위/변조 되지 않음을 보장.

TLS를 사용하지 않으면 패킷을 쉽게 확인할 수 있지만, tls를 쓰면 복호화 전에는 패킷 내용 알 수가 없다.

### 요약

1. TLS는 응용계층과 전송계층 사이에서 데이터의 암/복호화를 책임진다.
2. 상대방의 신원확인, 메시지의 무결성 보장을 한다.
3. tcp 443포트를 사용한다.
4. https의 기반 기술이다.

> 궁금한 점: TLS가 응용계층과 전송계층 사이라고 했는데, 그 사이에는 프레젠테이션 계층과 세션 계층이 있음. 정확히 얘기하면 보낼 땐 응용계층과 프레젠테이션 계층 사이인거고, 받을 땐 전송계층과 세션계층의 사이인건지...?



---

## 27. [Latency & Bandwidth - 효오](https://www.youtube.com/watch?v=mFBIwEhvZUY&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=30)<a name = "Latency_&_Bandwidth_효오"></a>

레이턴시는 하나의 데이터 패킷이 한 지점(출발지점)에서 다른지점(도착지점)으로 전송되는 데 걸리는 시간을 말한다. 네트워크의 하드웨어, 운영 시스템 별로 다양한 원인 등이 있어서 복잡하다.

밴드위스는 네트워크나 데이터 전송 매체의 데이터 운반 능력을 말한다. 단위 시간동안 한 지점에서 다른 지점으로 전달될 수 있는 최대 데이터 양을 의미한다.

웹 성능을 높이려면 레이턴시 낮추고 밴드위스 높이면 된다. 근데 그렇게 한다고 무조건 되는 건 아니고, 만약 앞에 있는 패킷들이 멈춰버리면 지연이 생김. 예를들어, 대역폭을 아무리 늘린 들 앞 데이터가 멈추면 지연이 생김. 따라서, 대역폭보다는 지연시간에 우선순위를 두는 게 좋을듯(둘 다 신경써야 하긴 함).

레이턴시를 낮추려면 클라이언트와 서버의 거리를 고려해야하고, 브라우저 캐시를 구성해야하고, 병목현상을 파악/해결해야하고, 적은 리소스를 로드하고, http2를 사용해야 함.

밴드위스를 높이려면 대역폭 제한 설정, 돈 쓰면 될듯.

실습 - 핑 쏘면 레이턴시 볼 수 있음, 크롬 - 개발자도구 - 네트워크 - 온라인에 slow3G로 바꾸면 느린 환경에서 웹이 어떻게 작동하는 지 볼 수 있음.



---

## 28. [HTTP 2.0 - 아이크](https://www.youtube.com/watch?v=uhlvXrDpM-Y&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=31)<a name = "HTTP_2.0_아이크"></a>

http가 발전한 계기는 tcp의 성능이 별로라 http 성능도 별로고, 그래서 성능 개선을 하면서 발전함.

### HTTP1.~의 문제

1. 리소스: http 버전이 증가하면서 데이터 크기가 커지고 있음. 과거보다 한 화면 당(?) 요청도 많아짐. 아무리 대역폭을 늘려도 tcp의 성능이 저하됨...

2. 데이터 전송: http 1.0에서 3-way handshake가 도입됐는데 이게 시간이 많이 걸림. 1.1에서는 지속커넥션을 도입해서 속도를 개선함. 하지만 다음 요청을 보내기 위해선 이전 요청에 대한 응답을 받아야 한다는 문제가 남음. 이걸 해결하기 위해 pipelining 기법 도입. 이건 받는 쪽에서 요청을 받는 큐를 두고, 순차적으로 처리. 어느정도 해결됐지만, 처음 요청한 요청에 문제가 발생하면 다음 요청에 대한 처리가 느려짐(순차적이기 때문). 처음 요청의 병목으로 인해 레이턴시가 증가할 수 있음. 이를 해결하기 위해 도메인 샤딩 방식이 도입됨. 같은 서버의 도메인 명을 다르게 해서, 리소스를 나눠 저장하는 것. 요청이 들어오면 나눠진 리소스를 병렬적으로 응답. 이 때 도메인마다 커넥션을 맺고 끊어야하고, 상당 시간, 대역폭을 소모하고, 연결할 수 있는 커넥션 수가 제한돼있다는 문제가 남음.

결론: 노력했지만 tcp 성능을 근본적으로 해결하지 못했다. => http 2.0이 나옴.

### HTTP 2.0의 목표 

1. 멀티플렉싱으로 레이턴시를 줄이기 
2. 헤더압축으로 오버헤드를 최소화하기 
3. 서버푸시 지원.

### 멀티플렉싱

프레임은 http2.0에서 통신의 최소 단위를 말한다. 최소 하나의 프레임헤더를 가진다. 바이너리로 인코딩돼있디(원래는 바이너리 인코딩 없이 데이터 전달했음). 메시지는 프레임 여러개를 모은 것이다. 요청/응답의 단위이다. 여기까진 1.~랑 비슷하고, 2.0에서 달라진 건, 스트림이 도입됐다는 것이다. 스트림은 양방향 통신을 통해 전달되는 한 개 이상의 메시지이다. 즉 프레임 여러개 모이면 메시지, 메시지 여러개가 모이면 스트림이다. 스트림 기반으로 멀티플렉싱을 하면, 요청을 병렬적으로 처리하기 때문에 순차적인 것이 깨진다. 덕분에 tcp 성능 저하를 막을 수 있다.

### 헤더압축

데이터가 점점 커지고 있음... 이전까지 컨텐츠는 압축했는데 이제 헤더도 압축. HPACK이라는 압축방식 사용 - 헤더 인덱싱 후 인코딩. 클라이언트가 서버에 요청을 보내면 서버는 헤더테이블을 참조해서 이전에 전달된 헤더는 생략하고 새로 들어온 헤더는 데이터 갱신. 응답할 때 기존에 있는 거 있으면 인덱싱값만 전달해줘서 성능 향상.

### 서버 푸시

이전에는 예를 들어 웹페이지를 보여달라고 요청하면

1. html 요청
2. html 태그 파싱
3. 필요한 리소스(css, js, png...) 재요청
4. 웹페이지 완성

2.0에서는

1. html 요청
2. 웹페이지 요청(리소스 재요청 없음)

### HTTP 2.0의 한계

http2.0은 tls 기반이기 때문에, tcp의 3-way handshaking과 tls의 handshaking이 동시에 일어나서 성능상 문제가 발생함. 이걸 해결하는 게 http3.0. http3.0은 UDP를 활용해 통신 과정을 단순화할 수 있음.



---

## 29. [JVM의 Garbage Collector - 던](https://www.youtube.com/watch?v=vZRmCbl871I&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=32)<a name = "JVM의_Garbage_Collector_던"></a>



### JVM

JVM은 자바 프로그램이 운영체제의 메모리 영역에 접근하여 메모리를 관리할 수 있도록 해주는 프로그램이다. JVM의 역할은 메모리 관리, Garbage Collector 수행하는 것이다. 



### 가비지컬렉터

동적으로 할당한 메모리영역 중 사용하지 않는 영역을 탐지하여 해제하는 기능을 한다.

Stack은 정적으로 할당된 메모리이다. 원시 타입의 데이터가 값과 함께 할당됨. Heap 영역에 생성된 Object 타입 데이터의 참조값 할당됨.

Heap은 동적으로 할당된 메모리이다. 모든 Object 타입의 데이터가 할당됨. Heap영역의 Object를 가리키는 참조변수는 Stack영역에 할당됨.

메인이 실행되면 stack쌓이고, heap도 쌓임. main이 끝나면 stack에 있는 건 다 사라지고, heap에 있는 건 남는데, 이때 남은 heap 내 데이터를 Unreachable Object라고 함. 이 Unreachable Object가 가비지컬렉터의 대상이 됨.

#### 가비지컬렉터의 과정

1. 가바지컬렉터가 Stack의 모든 변수를 탐색하면서 각각 어떤 객체를 참조하는 지 찾아서 마킹함.
2. Reachable Object(마킹해놓은 객체)가 참조하고 있는 객체도 찾아서 마킹함.
3. 1,2과정을 거쳤는데도 마킹되지 않은 객체를 Heap에서 제거함.

1,2과정을 마크, 3을 스윕 이라고 함.

#### 가비지 컬렉션이 일어나는 시점

힙은 New Generation과 Old Generation으로 나눠져있음. New Generation은 Eden(처음 객체 할당됨), Survival 0, Survival 1로 나뉨. Eden에 메모리가 꽉차면 가비지 컬렉션 구동됨. 이 때 일어나는 가비지컬렉션을 Minor GC라고 함. 마크 앤 스윕 과정이 일어남. 이 Minor GC 후에 살아남은 객체를 Survival0으로 이동시킴. 이 과정을 반복해서, Survival0가 꽉차면 Survival0를 대상으로 GC 구동(마크 앤 스윕). Survival0에서 살아남은 애들은 Survival1으로 이동. 이 때 객체의 age값이 증가. 이 때 신기한게 다음 Eden이 꽉차서 GC를 하면 Survival0으로 이동하는 게 아니라, Survival1로 이동. 메모리가 차있는 쪽으로 객체를 옮기기 때문. 즉, Survival0이나 Survival1 둘 중 하나는 아예 비어있는 상태임. 이걸 반복하면 계속 살아남는 애들은 Survival0과 Survival1을 왔다갔다하면서 age가 늘어남. 특정 age값을 넘어서는 애들은 Old Generation으로 옮기고, 이걸 Promotion이라고 함. 이 과정이 반복돼서 Old Generation이 꽉차면 또 GC가 구동되는데 이걸 Major GC라고 함.

> 궁금한 점: Major GC를 했는데 가바지가 하나도 없어서 메모리가 계속 꽉 찬 상태면 어떻게될까?



#### 가비지 컬렉터의 종류

##### Serial GC

GC를 처리하는 스레드가 1개. CPU 코어가 1개만 있을 때 사용. Mark-Compack Collection 알고리즘 사용.

##### Parallel GC

GC를 처리하는 스레드가 여러개. Serial GC보다 빠르다. 메모리가 충분하고 cpu코어의 개수가 많을 때 사용.

##### Concurrent Mark Sweep GC

사전 지식 - stop-the-world: GC를 실행하기 위해 JVM이 애플리케이션 실행을 멈추는 것. 이게 발생하면 GC를 실행하는 스레드 외의 모든 스레드는 작업을 멈춘다. GC를 완료한 후 다른 스레드들은 중단한 작업을 다시 시작.

이 stop-the-world 기간을 줄임. - 이게 어떻게 진행되는지도 알려주심. 장점: stop-the-world 기간이 짧음 - 애플리케이션의 응답시간이 빨라야 할 때 CMS GC 사용. 단점: 다른 GC보다 메모리, cpu를 더 많이 쓴다. compaction 단계가 제공되지 않음.

##### G1 GC

영역들을 (eden 등) 다른 개념(region)으로 나눔. GC가 일어날 때 전체 영역(eden, survival, old generation)을 다 탐색하지 않고, 필요한 영역만 탐색함으로써 stop-the-world기간을 단축시킨다. compaction을 사용한다. 



## 30. [Apache MPM vs NGINX vs Node.js - 미스터코](https://www.youtube.com/watch?v=QeBqwwbsBbM&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=33)<a name = "Apache_MPM_vs_NGINX_vs_Node.js_미스터코"></a>



Apache MPM(multi-processing modules)는 서버는 시스템을 네트워크 포트에 연결하고, 요청을 받아들이며, 받아들인 요청을 처리하기 위해 자식들에게 분배하는 다중처리모듈(MPM)을 선택할 수 있다. NGINX 웹서버이다. Node.js 자바스크립트 런타임이다. 모듈, 웹서버, 런타임은 아예 다른 개념인데 왜 비교하지? **각각을 언제 써야하는 지 알아야 함.**

옛날이나 지금이나 동시성은 이슈. 동시성은 어느정도 기간동안 무시하지 않을 수 있는 연결(요청)들을 말한다.

옛날엔 너무 느린 네트워크가 문제였음. 응답준비에는 시간이 안드는데 응답전송에 시간이 많이 듬. 따라서 응답전송 기간동안 요청이 동시에 처리되게 하고싶었음.

요즘엔 기기가 많아짐(모바일, 태블릿 등). 연결을 계속 유지하고 있음. 브라우저 사용방식 변화됨(한 페이지로부터 여러 요청을 보냄). 그래서 요청들을 동시에 처리하고 싶음.

어떻게 동시성 이슈를 해결할까? 혼자 처리하기 힘들면 같이 처리하자.

### 동시성 이슈를 해결하는 방식

#### Apache MPM

커넥션 생성해줌. 커넥션 분배해줌(프로세스나 스레드에게). 즉 여러 요청이 왔을 때 요청을 분배해줌으로서 동시성 이슈를 풀려고 함(?).

- 모듈 종류(Unix 계열)

- prefork
  - 프로세스가 요청 처리
- worker
  - 스레드가 요청 처리
- event



하지만 Apache MPM으로는 아쉬움...

C10K Problem - 말도 안되게 많은 연결/요청(10000개)을 동시에 처리해야 한다면? 메모리 관점: 프로세스 1개 당 1MB가 필요하면 10GB가 필요한거고 컨텍스트 스위칭 관점: 코어가 4개면 잘 분배해도 하나 당 2500개씩 처리해야함. 이건 컨텍스트 스위칭이 2500개씩 일어난다는 것. 결국 메모리 이슈든 컨텍스트 스위칭 이슈든 요청 수에 비례하여 시간/용량이 든다는 문제가 있음.

동시에 처리해야 할 숫자에 영향을 받지 않으려면... 상수시간으로 만들어야 하는데



#### Node.js

비동기 이벤트 주도 자바스크립트 런타임으로서 확장성있는 네트워크 애플리케이션을 만들 수 있도록 설계됨. 싱글스레드를 돌려서 최대한 해야할 일만 할 수 있도록 하자. - 컨텍스트 스위칭 영향 줄이기. 기다려야 하는 시간을 최소화하자(비동기 + 이벤트 활용하여...). 이벤트활용: 이벤트들을 큐에 등록하고 하나씩 실행시킴 - 다음에 어떤 일을 할 지 커널에 맡기는 게 아니라, 자체적으로 스케쥴링.

##### Node.js 사용 시 주의할 점

하나의 흐름(함수 등)이 끝나기 전에는 다른 흐름을 실행할 수 없다는 걸 인지해야 함. 따라서 CPU가 많이 필요한 작업에는 Node.js 사용에 주의를 기울여야 함. 조심해야 하는 입력들 예시: 정규표현식, synchronous expensive api : 암호화, 파일io, dns에 요청, 프로세스 fork, JSON DOS



#### NGINX

확장성에 대한 대응 방식은 Node.js와 비슷. 웹서버라는 역할에 최적화됨. 웹서버라는 것은 요청들이 정적이라는 의미일 수 있고(cpu점유를 적게 하는), 따라서 비동기방식에 적합하다고 볼 수 있다.

##### NGINX 사용예

- 로드밸런서
  - 효율성
  - 안전성(누가 죽어도 다른애가 살아있음)

- 리버스프록시
  - 보안
  - 유연성(외부에서 서버를 직접 모르기에)
  - 레이턴시 감소
    - 압축
    - SSL(암호화)
    - 캐시

재밌는 게 node.js에서 주의해야했던 걸 여기에서는 주의하지 않아도 됨. 예를 들어, cpu가 많이 드는 애들을 조심해야 했었는데 Node.js가 리버스 프록시 역할을 해주면 안그래도 돼(WAS의 부담 덜어감).



### 결론

Apache MPM, NGINX, Node.js의 공통점은 동시에 많은 연결과 요청이 있어도 그 숫자에 성능이 영향을 받지 않도록 하기 위한 노력을 한다는 점이다.

> 추가사항: cpu, 메모리 등이 병목이 될 수 있다고 얘기했지만 그거 말고도 병목 될 수 있는 부분들이 있음 : Connection을 많이 생성 못하면 병목이 생길 수 있음.



## 31. [Web polling vs Web push - 유니](https://www.youtube.com/watch?v=v11dxmc5a0I&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=34)<a name = "Web_polling_vs_Web_push_유니"></a>



### 웹 폴링과 웹 푸시가 필요한 이유

정적 웹 페이지 - 미리 저장된 파일을 그대로 전달. 동적 웹 페이지 - 사용자의 요청을 해석해서 파일을 동적으로 생성하여 전달. 

정적이든 동적이든 결국 완전한 html파일을 보여줘야 함 - 일부 정보만 변경돼도 완전히 페이지를(모든내용) 새로 가져와야 함.

=> 실시간 웹으로 해결하고자 함(페이지의 현재상태를 방해하지 않고 서버와 통신).

**web polling과 web push가 실시간 웹을 가능하게 하는 기술임.**

web polling은 기존 요청/응답을 푸시처럼 보이게 만드는 기술이다. web push은 요청 없이 서버에서 클라이언트러 정보 전달한다.

### Web Polling

polling : 충돌 회피 또는 동기화 처리 등을 목적으로 상태를 주기적으로 검사하여 조건을 만족할 때 자료를 처리하는 방식. 클라이언트가 주기적으로 서버에 요청해서 정보를 전달받음. 실시간 메시지 전달이 크게 중요하지 않은 곳에 쓰면 됨(주기적이기만 하면 될 때). 불필요한 요청/응답이 발생할 수 있음.

long polling: 클라이언트가 보낸 요청을 서버가 가지고 있다가 이벤트 발생 시 정보를 전달받음. 실시간 메시지 전달이 필요할 때 씀. polling에 비해 불필요한 요청/응답이 덜 발생.

### Web Push

1. web socket: tcp연결을 통해 양방향 데이터 통신 제공. 클라이언트가 서버에 요청할 때 upgrade 속성을 추가하고, 서버가 웹소켓을 지원하면 http에서 ws(wss)로 바뀜. - 양방향 통신 가능.

2. server sent events(sse): http연결을 통해 서버에서 클라이언트로 데이터를 송신 가능하게 함. 연결된 상태를 유지하고 서버가 클라이언트에 일방적으로 데이터 전송(단방향) 사용자는 메시지를 구독해야 함. 자동재연결함. 연결이 닫히면 브라우저가 3초 후 자동으로 소스(?)에 다시 연결됨.



---

## 32. [JVM Stack & Heap - 무민](https://www.youtube.com/watch?v=UzaGOXKVhwU&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=35)<a name = "JVM_Stack_&_Heap_무민"></a>

C, C++ 등은 컴파일 플랫폼과 타겟 플랫폼이 다를 경우 프로그램이 동작하지 않는다. os별로 지원하는 시스템 콜 인터페이스가 다르고, cpu아키텍처가 지원하는 ??(못들음) 아키텍처가 다름. 여기에서 플랫폼은 운영체제 + cpu 아키텍처를 말한다. 개발할 때는 문제가 없음. 리눅스에서 컴파일하고 리눅스에서 돌릴테니까. 배포할 때 문제가 생김. 리눅스에서 컴파일한 걸 윈도우에서 돌린다거나 하니까. 이를 해결하기 위해 C 진영은 크로스컴파일이라는 걸로 해결했는데, 타겟 플랫폼(배포환경)에 맞춰 컴파일하는 것.

### JVM

자바진영은 위 문제를 JVM으로 해결. JVM은 자바 바이트코드를 실행하는 가상의 기계이다. 자바소스코드가 javac라는 컴파일러를 거치면 자바바이트코드가 됨. 자바바이트코드든 플랫폼 상관없이 jvm이 설치돼있기만 하면 작동함. jvm이 플랫폼과 관련된 지저분한 작업을 해주기 때문임. 즉, 네가 짠 코드를 컴파일해서 배포하면, 어떤 플랫폼이든 다시 컴파일할 필요 없이 실행시킬 수 있어! 근데 실행하려면 플랫폼에 맞는 JVM이 설치돼있어야 해.

크로스컴파일하면되는데 JVM으로 해결하는 이유? 자바의 목적 자체가 네트워크에 연결된 모든 기기에서 작동하는 것이엇기 때문. 디바이스마다 하드웨어가 다르기 때문에 플랫폼에 의존하지 않도록 언어를 설계함. 자바의 야심: 웹서버에 .class파일이 있고, 이 .class파일을 네트워크를 통해 전달해주면 웹브라우저, 모바일 등에 jvm을 설치시켜놔서 실행가능하게 하기. 이게 현재 자바에선 안되고 자바스크립트 쪽에서 됨... 자바스크립트 파일을 넘겨주면 웹브라우저 자바스크립트 런타임이 그걸 실행해버림.

컴파일러에도 프론트엔드, 백엔드가 있음. 컴파일러에서 프론트엔드는 플랫폼에 따라 바뀌지 않고(사람이 쓴 코드의 의미를 파악하는 역할을 하기 때문 - 플랫폼이랑 상관이 없음), 백엔드는 플랫폼에 따라 바뀜(어셈블리어가 운영체제, 디바이스에 디펜던트하기 때문). 백엔드만 윈도우용, 리눅스용 이렇게 달라짐. C에선 프론트엔드, 백엔드를 다 하나의 컴파일러가 함. 자바에선 프론트엔드 - javac, 백엔드 - jvm이 함.

### JVM 내부구조

주목할 부분은 runtime data areas: jvm이 자바바이트코드를 실행하기위해 사용하는 메모리공간(자바바이트코드를 실행할 때 여러 공간이 필요..). 이 중 스레드가 공유하는 것: method area, heap.

#### runtime data areas

1. method data: class data 저장. 클래스로더가 클래스 파일을 읽어오면 클래스 정보를 파싱해서 method area에 저장. 변수가 어떤 게 있는 지, method가 어떤 게 있는가, 정적 변수는 뭐인가 등.

2. heap: 프로그램을 실행하면서 생성한 모든 객체를 저장.

스레드가 공유하지 않는 것(스레드별로 가짐): java stacks, pc registers, native method stacks.

3. program counter: 각 스레드는 어떠한 메소드를 항상 실행하고 있음. pc는 그 메소드에서 몇 번째 줄을 실행해야 하는 지를 알려주는 역할을 함.

4. 자바스택: 스레드별로 한 개만 존재. 스택프레임은 메소드가 호출될 때마다 생성됨. 메소드 실행이 끝나면 스택프레임은 pop되어 스택에서 제거됨. 맨 위의 스택프레임은 main method. main method에서 호출하는 게 있으면 스택프레임이 만들어져서 쌓임. 스택프레임은 Local variables array, Operand stack, Frame data를 갖는다. Frame data는 Constant Pool, 이전 스택 프레임에 대한 정보, 현재 메소드가 속한 클래스/객체에 대한 참조 등의 정보를 갖는다. 이것들은 바이트 코드를 실행하기 위해 당연히 필요한 정보들임(지금 실행하는 메소드가 어떤 클래스에 속하는 지 등은 당연히 필요).

5. Native method stack: 자바바이트코드가 아닌 다른 언어로 작성된 메소드를 의미.

인텔리제이 플러그인을 활용하여 실제로 코드가 어떻게 바이트코드로 바뀌는 지 보여주심.

cpu는 register를 사용하여 어셈블리어를 돌리는데, jvm도 가상의 기계인데 왜 register(연산, 피연산등을 원래 여기에 저장)를 안쓰고 stack을 쓸까? 자바의 야심때문... 디바이스마다 레지스터수는 다르기 때문에 레지스터를 쓰는 순간 자바의 야심을 포기해야 함. stack을 쓰면 계산과정은 좀 더 복잡하지만, 하드웨어 스펙에 최소한 관여하게 됨.



---

## 33. [CORS - 코나스](https://www.youtube.com/watch?v=_sLjXviYivM&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=36)<a name = "CORS_코나스"></a>

### 동일출처정책

동일출처정책(SOP-same origin policy): 어떤 출처에서 불러온 문서나 스크립트가 다른 출처에서 가져온 리소스와 상호작용하는 것을 제한하는 보안 방식.

> 궁금한 점: sop가 없으면 어떤 문제가 생길까?

출처가 같다는 건 두 url의 프로토콜, 호스트, 포트가 모두 같다는 것.

### 크로스 도메인 이슈

sop때문에 자바스크립트로 다른 웹페이지에 접근할 때 같은 출처의 페이지만 접근 가능. sop를 우회하여 서로 다른 도메인 간 통신할 수 있게하는 무언가가 필요해짐. 해결책을 예로 들자면,

- JSONP
- Reverse Proxy
- Flash Socket

### CORS의 등장

크로스도메인이슈를 해결하는 표준이 필요해짐 - W3C에서 권장사항으로 CORS 사양 발표함. 현재 활발하게 유지되는 사양은 WHATWG의 'Fetch Living Standard'.

CORS(Cross origin resource sharing)는 웹 브라우저에서 외부 도메인 서버와 통신하기 위한 방식을 표준화한 스펙임. 서버와 클라이언트가 정해진 헤더를 통해 서로 요청이나 응답에 반응할 지 결정함.

#### CORS의 동작방식

1. 간단한요청(Simple Requests): 기존 데이터에 부작용을 일으키지 않는 요청. 사전요청을 발생시키지 않는 요청. 조건은 아래와 같음. 

- GET, HEAD, POST중 한 가지 방식 사용.
- Custom Header가 존재하지 않음.
- POST일 경우 Content-type이 아래 셋 중 하나여야 함.
  - application/x-www-form-urlencoded
  - multipart/form-data
  - text/plain
- 예시: origin을 포함한 겟 요청 시, 서버는 자기가 허용한 크로스 오리진인지 확인 후 응답.

2. 사전요청(Preflight Requests): 본 요청을 보내기 전에 사전 요청을 보내 서버가 응답 가능한 지 먼저 확인.

   사전 요청을 보내는 경우:

- GET, HEAD, POST 이외의 요청

- POST요청이지만 허용하는 세 가지 content-type에 해당되지 않을 때

- 커스텀헤더가 포함돼있을 때

  사전요청 과정

  1. 브라우저가 서버에 OPTIONS method로 요청(preflight request)
  2. 서버는 자기가 허용하는 method, 허용하는 헤더, 쿠키 허용 여부 등을 응답(preflight response).
  3. 브라우저는 서버의 응답을 보고 허용되겠다 싶으면 본요청을 보냄.
  4. 서버가 진짜 응답을 함.

3. 인증을 이용하는 요청(Credential Requests)

   XHR은 기본적으로 요청을 할 때 쿠키를 보내지 않음. 요청에 쿠키를 포함하고 싶다면 XMLHttpRequest 객체의 withCredentials 프로퍼티 값을 true로 설정. 서버도 Access-Control-Allow-Credentials 응답 헤더를 true로 설정.



## 34. [scale up vs scale out, SPOF - 포도당](https://www.youtube.com/watch?v=6wPr2jgdDxM&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=37)<a name = "scale_up_vs_scale_out,SPOF_포도당"></a>

내일 당장 일을 끝내려면... 여러 친구들에게 부탁하거나 나 자체가 스페셜리스트가 되야함.  여러 친구들(서버들)에 요청하는 게 scale out, 나 자체가 스페셜리스트가 되는 게 scale up.



### Scale Up

서버 자체를 증강시켜 처리 능력 향상. 수직 스케일.

#### 장점 

1. 구축, 설계가 쉬움.

2. 컨트롤러나 네트워크 인프라 비용은 별도로 발생하지 않음.

#### 단점

1. 스토리지 컨트롤러의 확장성 한계

2. 용량, 성능 확장의 제한

3. 비쌈

4. 트래픽 부하로 인한 장애 영향도 up

#### 주요 기술

1. 고성능 cpu

2. memory 확장

3. ssd



### Scale Out

서버의 대수를 증가시켜 처리능력 향상. 수평 스케일.

#### 장점

1. 지속적인 확장 가능.

2. 분산처리 -> 장애 가능성 줄임

3. 상대적으로 저렴.

#### 단점

1. 설계, 구현이 복잡함 - 관리 비용 증가.

2. 기본적인 직렬화 존재.

3. 병렬성, 대역폭 등 기술적인 문제 존재.

4. 코어 개수와 성능이 비례하지 않음.

#### 주요 기술

1. 샤딩

2; 인메모리캐시

3. nosql



### scale up vs scale out

#### scale up 언제 쓰면 좋을까?

1. 정합성 유지가 어려운 경우

2. OLTP(온라인 트랜잭션 처리)

3. 데이터베이스 갱신을 요구하는 서버일 때

4. 비즈니스 프로세싱

#### scale out 언제 쓰면 좋을까?

1. 높은 병렬성을 실현하기 쉬운 경우.

2. 정합성 유지가 쉬운 경우.

3. 메일 게시판 서버, 데이터 읽기 전용 어플리케이션, 웹 서버 등.

3. 웹 인프라스터럭쳐, 어플리케이션 개발

scale up: 비싸봤자 성능이 엄청 좋아지지 않는다(?).

scale out: 일정수준까지는 성능이 팍팍 올라가지만 복잡성때문에 어느 수준까지만 올림.



### SPOF(single point of failure, 단일장애점(고장점,실패점))

전체 시스템 중 일부가 에러 나면 전체 시스템이 중단됨. 예를 들어 라우터가 고장나면 통신이 안되지.

#### 예방하는 방법

1. 복잡한 시스템인지 판별하기

2. 단일장애점 파악 및 제거하기

3. 높은 신뢰성이 필요하면 단일컴포넌트에 의존하지 않게 한다.

구체적으로 복잡성을 낮추고, 복제하고, 다양하게 하고, 문서화하자.

소프트웨어 관점에서 생각하면 

#### 웹브라우저가 웹서버에 요청을 할 때 

로드밸런스 부분이 SPOF. 그래서  n대의 웹서버를 두고, L4, L7 스위치를 둠.

#### 웹서버에서 와스로 갈 때

대부분 개발자의 코드로 인해 문제점이 발생. n대의 was 구축하기.

#### 데이터베이스에선

보통 용량 부족으로 인해 장애 발생함. RAID, NAS 등을 적용하기.



---

## 35. [트랜잭션 메커니즘 - 에이든](https://www.youtube.com/watch?v=ImvYNlF_saE&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=38)<a name = "트랜잭션_메커니즘_에이든"></a>



### 트랜잭션은 왜 필요한가?

계좌이체를 통한 결제는 다음 두 가지 과정을 거침.

1. 구매자의 계좌에서 돈이 출금됨
2. 판매자의 계좌에 돈이 입금됨.

이 과정에서 오류가 발생한다면?

예상되는 오류

- 구매자의 계좌에서 돈이 출금된 후 DB가 다운됨.
- 구매자의 계좌에서 돈이 출금되지도 않았는데 판매자에게 돈이 입금됨.
- 출금도 입금도 되지 않음.

어떻게 오류가 나지 않게 할까? **어중간한 상태는 안돼. 다 되거나 다 안되게 하자.**



### 트랜잭션 동작 원리

1. 쿼리에 트랜잭션 시작과 끝 명시.

2. 쿼리 수행을 위해 데이터 캐시 확인

3. 캐시에 데이터가 없으면 데이터 파일에서 데이터 가져옴

4. 데이터 캐시에 필요한 데이터가 로드됨

5. 로그에 변경 후의 값을 기록(ReDo로그)하고, 변경 전의 값을 기록(UnDo로그)함.

6. 데이터 캐시의 데이터 변경함.

7. 트랜잭션 중간에 오류가 난다? 롤백! 롤백은 UnDo로그를 보고 수행.

만약에 롤백하지 않았는데 OS에서 문제가 생기거나, 하드웨어가 꺼지거나 등 예상치 못한 오류가 생길 땐

ReDo로그를 활용하여 데이터들을 다시 일관성있게 만들어줌. 그 이후 UnDo로그를 활용하여 롤백.

트랜잭션 스타트가 있는데 커밋이 안됐다? 이전 상태로 돌려주자.

만약에 데이터에 동시 접근이 가능하다면 원하는대로 로직처리가 안될 가능성이 있음. 이를 방지하기 위해 락 활용. 트랜잭션이 시작되면, 이용하는 row, table은 트랜잭션이 끝날 때까지 점유한다.



## 36. [DB Optimizer - 버디](https://www.youtube.com/watch?v=dP0MIgyrqlo&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=39)<a name = "DB_Optimizer_버디"></a>

왜 최적화해야하는가? DB에서 데이터를 조회하고 저장하는 시간이 서버의 70%이상을 차지함. 그만큼 이걸 줄이는 게 중요함.

### 쿼리처리의 흐름

1. 사용자가 쿼리를 작성하여 요청

2. 파서가 문법상 오류가 없는 지 확인하고, db가 이해하기 쉽게 sql을 잘개 쪼갬. 그걸 optimizer에 전달함.

3. optimizer는 전달받은 파싱된 쿼리를 보고 여러 실행 계획을 세우고, 각각 비용을 평가한 후 가장 좋은 실행계획을 선택.

4. 비용평가는 카탈로그 매니저(통계정보저장소)에 들어있는 통계정보를 바탕으로 평가.

즉, Optimizer는 파싱된 쿼리의 인덱스 유무, 데이터 분산/편향 정도 등의 정보를 참고하여 여러 실행계획을 작성하고, 통계정보를 참고하여 이것들의 비용을 연산하고, 가장 낮은 비용의 실행계획을 선택함. 그런데 Optimizer의 한정된 통계정보로 인해 최적화를 못할 수도 있음. 이 때 우리가 실행계획을 바꿔야 함.

### 실행계획

SQL에서 요구한 사항을 처리하기 위한 절차와 방법을 의미함 - 테이블을 어떻게 세팅할 지, 어떤 인덱스를 쓸 지 등을 작성해놓은 표라고 보면 됨. 각 테이블에 대한 스캔 방식도 다르고 인덱스 등도 다르기 때문에 같은 결과를 내는 방법(실행계획)이 여러가지임. 따라서 각각의 비용을 계산해봐야 함. 실행계획을 보기 위해 mysql에선 explain + SQL문 사용. 쿼리를 했는데 성능이 영 아니다? 실행 계획을 분석하자. type에 테이블을 어떻게 스캔할 지에 대한 정보가 담겨있음(예를 들어 All이면 모든 row를 스캔하겠다는 것). rows에는 접근한 row 수가 나옴. extra: 그 외 어떻게 쿼리를 수행했는 지(?) 정보가 나옴.

full table scan은 일반적으로 별로이지만, 좋을 때도 있음.

- table 크기가 작을 때
- 조건절이 없을 때
- 조건에 일치하는 레코드 수가 많을 때

반대로, 위와 다를 때 안좋음. => 인덱스 스캔이 좋을 수 있음.

인덱스 스캔 시 인덱스 선정 기준: Index Range Scan의 가능 여부에 따라 인덱스를 정함(?).

실행계획에 따라 성능차이가 엄청나기 때문에 실행계획을 잘 짜는 게 중요함.

> 궁금한 점: 웬만하면 옵티마이저가 최적의 실행계획을 골라주고 특수한 경우에만 수동으로 실행계획을 짜주면 되는건지, 대부분의 상황에서 실행계획을 신경써야하는 지 궁금. 예시는 일반적인 상황인 것 같은데 실행계획을 직접 짜주니 성능 차이가 많이나서...



## 37. [SQL 인젝션 - 로비](https://www.youtube.com/watch?v=qzas_-u4Nxk&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=40)<a name = "SQL_인젝션_로비"></a>

SQL인젝션: 데이터베이스와 연동된 웹어플리케이션에서 공격자가 입력 가능한 폼에 조작된 질의문을 삽입하여 웹서비스의 데이터베이스를 열람하거나 조작할할 수 있는 공격.

### 피해사례

1. 여기어때에서 많은정보가 유출됨.

2. 뽐뿌 sql인젝션때매 해킹당함.

### 공격

예를들어 로그인할 때 id, pw에 sql을 삽입하여 어플리케이션의 db 조작.

### 방어

파라미터 바인딩 - 파라미터가 쿼리문에 직접 들어가버리면 사용자가 쿼리를 조작할 수 있다는 뜻. 쿼리문에 ?  넣고 setString 해주면 됨(PreparedStatement가 파라미터바인딩을 지원해줌). 왜 파라미터바인딩이 안전할까? 이 파라미터가 위험한 지 검증을 하고 안전하게 바꿔주기 때문.

SQL 인젝션은 흔하고 강력한 공격이지만 방어는 간단 - 파라미터바인딩을 하면 됨!



---

## 38. [Clustered vs Non-clustered Index - 올라프](https://www.youtube.com/watch?v=js4y5VDknfA&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=41)<a name = "Clustered_vs_Non-clustered_Index_올라프"></a>

### Non-Clustered Index

키에 데이터의 포인터를 두고, 밸류에 데이터를 둠. 인덱스의 구조는 데이터 행과 독립적. 한 테이블에 여러 개 생성 가능.

### Clustered Index

데이터를 인덱스로 지정한 컬럼에 맞춰 정렬. 인덱스가 테이블 구조에 영향을 미침. 한 테이블에 하나만 생성 가능. 검색이 빠름.

### InnoDB

pk는 항상 clustered index. unique index로 정의된 칼럼 중 하나. pk가 없으면 보이지 않는 칼럼을 추가하여 사용.

### Multicolumn Index

조건절에 두개 이상의 칼럼이 들어갈 때 인덱스가 하나면 느릴 수 있음. 멀티인덱스가 설정돼있으면 더 빠름.



---

## 39. [Sharding, Clustering, Replication - 히브리](https://www.youtube.com/watch?v=y42TXZKFfqQ&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=42)<a name = "Sharding,Clustering,Replication_히브리"></a>

디비 관련 한정하심.

세 가지의 공통점: 데이터베이스를 여러개로 만든다. 목적이나 어떤 요소를 나누느냐에 따라 세가지로 나눠짐.

기본 데이터베이스는 데이터베이스 서버 - 데이터베이스 스토리지로 구성됨.

### 클러스터링

배경: 데이터베이스 서버가 죽으면 어떻게하지?

데이터베이스 서버를 여러개로 만들자! 이게 클러스터링.

#### active-active 클러스터링

DB 클러스터를 두고, 그 안에 여러개의 active 데이버베이스 서버를 둠. 장점: 몇개 죽어도 괜찮음. 여러개 두는 만큼 cpu를 충분히 활용할 수 있음. 단점: 스토리지를 공유하기에 병목이 생길 수 있음. 여러개 운영해야하기에 비쌈.

#### active-standby 클러스터링

하나는 액티브로 두고, 나머지는 standby 시키고 액티브가 문제생겼을 때 standby를 액티브로 변환. 단점: 문제가 생겼을 때 스탠드바이를 액티브로 바꾸는 데 시간이 걸림. 장점: 스탠드바이를 운영안해도 되기 때문에 비용 절감.



### Replication

배경: 저장된 데이터가 손실되면 어떡하지?(클러스터링 시 스토리지는 하나였음...)

마스터디비와 슬레이브디비로 나눠 슬레이브 디비에 마스터디비를 백업해놈. 나아가 슬레이브디비를 백업용 뿐 아니라 부하분산에 쓸 수도 있음.



### sharding

배경: 데이터가 너무 많아서 검색이 느린데 더 빠르게 할 수 있는 방법은 없을까?

테이블을 나눠서 검색하자!

테이블을 row단위로 나눠서 각각 샤드라고 칭함. 데이터 검색 시 어느 샤드에만 있는 지 알면 빨리 검색할 수 있음.

#### 샤딩할 때 고려할 점

1. 분산된 데이터베이스에 데이터를 어떻게 잘 분산시킬까?

2. 분산된 데이터베이스에서 어떻게 데이터를 잘 읽을까?

=> 고려하면서 나온 게 샤드 키

#### 샤드키

나눠진 샤드 중 어떤 샤드를 선택할 지 결정하는 키. 샤드키 결정방식에 따라 샤당 방법이 나뉨.

1. 해시샤딩: 샤드들을 해싱해서 나눠놈. 그냥 해싱하면 돼서 구현이 쉬움. 하지만 해시함수가 바뀌면 기존 데이터의 정합성이 깨지게 되어, 확장성이 안좋음. 단순히 키를 기준으로 나누기 때문에 공간의 효율성을 고려하지 않음.
2. 다이나믹샤딩: 로케이터서비스라고 범위를 둠(?). 샤드가 하나 추가돼도 로케이터서비스에 샤드키 추가하기만 하면 됨. 대신 로케이터서비스에 샤드들이 종속되기 때문에 로케이터서비스에 문제가되면 샤드들에 문제가 생김.
3. Entity Group: 해시샤딩, 다이나믹샤딩은 nosql에 적합한건데, 이건 rdbms에 적합. 관계가 있는 애들을 같은 샤드에 둠. 단일 샤드 내에서 쿼리가 효율적이지만 샤드 간 쿼리가 필요하면 느림.

데이터베이스를 나눈다고 무조건 좋은 게 아니라, 상황에 맞춰서 의사결정하자.



---

## 40. [JDK Dynamic Proxy vs CGLIB Proxy - 미르](https://www.youtube.com/watch?v=RHxTV7qFV7M&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=43)<a name = "JDK_Dynamic_Proxy_vs_CGLIB_Proxy_미르"></a>

Proxy: 자기가 클라이언트가 사용하려는 대상인 것처럼 위장해서 클라이언트의 요청을 받아주는 것. 타깃과 같은 메소드를 구현하고 있다가 메소드가 호출되면 타깃에게 위임해주고 부가기능 수행해줌.

### Proxy 문제점 

매번 새로운 클래스를 정의해야함. 타깃의 인터페이스를 구현하고 위임하는 코드를 작성하기가 번거로움. 부가기능 코드의 중복이 생김.

=> 이 부분을 해결하기 위해 JDK Dynamic Proxy가 나옴.

### JDK Dynamic Proxy

프록시 팩토리에 의해 런타임에 다이나믹하게 만들어지는 오브젝트. 프록시 팩토리에게 인터페이스 정보만 주면 그 인터페이스를 구현한 클래스 오브젝트가 자동으로 생성됨. 따라서 인터페이스가 꼭 존재해야함. 부가기능 코드(InvocationHandler)는 직접 작성해야함. ProxyService 인터페이스를 구현하고, 부가기능을 넣고싶으면 부가기능 코드 작성. JDK Dynamic Proxy를 쓰려면 꼭 인터페이스를 만들어야하는데, 이게 귀찮아서 CGLIB Proxy 나옴.

### CGLIB Proxy

프록시팩토리에 의해 런타임 시 다이나믹하게 만들어지는 오브젝트. 클래스 상속을 이용하기 때문에 인터페이스가 없어도 괜찮음. 부가기능 코드는 직접 작성해줘야 함. 이전에 CGLIB Proxy를 쓰지 않은 이유: Enhancer 의존성 추가해줘야하고 Default 생성자 필요하고 타깃의 생성자가 두 번 호출됨. 현재 CGLIB Proxy를 쓸 수 있는 이유? Enhancer 의존성 추가하지 않아도 Spring Core에 추가됐고 Default생성자도 필요없게되고, 타깃 생성자 호출 두번 호출도 안해도 되게 됨.



---

## 41. [AOP - Advice, Target, Pointcut - 뚱이](https://www.youtube.com/watch?v=WQR_VQnz7Yg&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=44)<a name = "AOP_Advice,Target,Pointcut_뚱이"></a>

AOP가 나온 배경: 부가기능을 추가하기 어려움. 

AOP: 여러 오브젝트에 나타나는 공통 부가기능을 모듈화하여 재사용하는 방법.

어떤 부가기능을 언제사용할까에 대한 정의 : Advice. 언제 사용할까에 따라 Advice가 다름.

어디에 사용할까에 대한 정의 : Pointcut, Joinpoint. Jointpoint: 어드바이스가 적용될 수 있는 위치. Pointcut: 어드바이스를 적용할 조인포인트를 선별하는 작업.

타겟: 부가기능을 적용할 대상.

AOP는 성능검사, 트랜잭션처리, 로깅 등에 쓸 수 있음.



---

## 42. [Sticky session & Session Clustering - 마틴](https://www.youtube.com/watch?v=gzKf2BTZToQ&list=PLgXGHBqgT2TvpJ_p9L_yZKPifgdBOzdVH&index=45)<a name = "Sticky_session_&_Session_Clustering_마틴"></a>

이것들이 나온 배경: 한 서버가 모든 트래픽을 감당하다보니 문제가 생겼고, 해결하기 위해 로드밸런싱이 나옴.

로드밸런싱을 적용하고 로그인했을 때 문제가 있음. 서버 A에 Key: Session Id, Value: 회원id 이렇게 관리함. 로그인 후 내 정보를 조회하는 트랜잭션은 서버B로 요청이 가면, 세션정보가 없어서 조회실패. 따라서 Session을 잘 관리할 필요가 생겼음

### Session 잘 관리하는 방법

- Sticky Session
- Session Clustering
- Session Server 따로 두기

### Sticky Session

클라이언트가 첫 리퀘스트에 응답 준 서버에 껌딱지처럼 붙어있는 것. 특정 세션의 요청을 처음 처리한 서버에만 보내는 것. 일반적으로 쿠키를 사용하거나 클라이언트의 ip를 트래킹하는 방식으로 구현함.

단점:

- 로드밸런싱이 잘 동작하지 않게될 수 있음.
- 특정 서버에만 과부하가 올 수 있음.
- 특정 서버 Fail 시 해당 서버에 붙어있는 세션이 소실됨.

### Session Clustering

스티키세션의 단점 극복하기 위해 나옴. 여러 와스의 세션을 동일한 세션으로 관리. 세션을 하나로(클러스터로 묶어서) 관리. 

단점: 새로운 서버가 하나 뜰 때마다 기존 와스에 새로운 서버의 ip,포트 정보를 입력해서 클러스터링 해줘야하는 번거로움이 있음.

### 세션 서버를 분리

세션 클러스터링의 단점 극복. 그냥 그 세션 서버에 세션정보 넣어주기만 하면 됨.
